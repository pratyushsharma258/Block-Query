{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf8237b-d50a-4dc9-a294-2bb422847ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, \n",
    "    LSTM, \n",
    "    Dense, \n",
    "    Embedding, \n",
    "    Dropout, \n",
    "    TimeDistributed, \n",
    "    Masking,\n",
    "    LayerNormalization,\n",
    "    Concatenate\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, \n",
    "    ReduceLROnPlateau,\n",
    "    ModelCheckpoint\n",
    ")\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7726a-64d0-4035-9314-6bd042f276c5",
   "metadata": {},
   "source": [
    "# Initial simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025678ad-12e5-43a4-8d98-d53622791519",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUESTION_LENGTH = 50\n",
    "MAX_ANSWER_LENGTH = 100\n",
    "EMBEDDING_DIM = 256\n",
    "LATENT_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0b1ce-06b8-4f0b-9907-da32dd9395e0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d124379-52fe-4757-b295-e1d9abd29d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    data = []\n",
    "    for file in sorted(os.listdir(dataset_path)):\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(dataset_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                content = json.load(f)\n",
    "                qa_pairs = content.get(\"qa_pairs\", [])\n",
    "                data.extend(qa_pairs)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb45723-d993-447e-be6b-e15a3804bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^a-zA-Z0-9.,!?\\'\"]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = f\"<START> {text} <END>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25753170-c459-4ea7-8a5a-e9f14a1e1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Clean text\n",
    "    df[\"question\"] = df[\"question\"].apply(clean_text)\n",
    "    df[\"answer\"] = df[\"answer\"].apply(clean_text)\n",
    "    \n",
    "    # Create tokenizers\n",
    "    question_tokenizer = Tokenizer(oov_token=\"<OOV>\", filters='')\n",
    "    answer_tokenizer = Tokenizer(oov_token=\"<OOV>\", filters='')\n",
    "    \n",
    "    # Fit tokenizers\n",
    "    question_tokenizer.fit_on_texts(df[\"question\"])\n",
    "    answer_tokenizer.fit_on_texts(df[\"answer\"])\n",
    "    \n",
    "    # Convert to sequences\n",
    "    question_sequences = question_tokenizer.texts_to_sequences(df[\"question\"])\n",
    "    answer_sequences = answer_tokenizer.texts_to_sequences(df[\"answer\"])\n",
    "    \n",
    "    # Pad sequences\n",
    "    question_padded = pad_sequences(question_sequences, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
    "    answer_padded = pad_sequences(answer_sequences, maxlen=MAX_ANSWER_LENGTH, padding='post')\n",
    "    \n",
    "    return question_padded, answer_padded, question_tokenizer, answer_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aff3e7-7a7a-455e-846b-aee25e35920e",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad15a1e-77d4-416c-bf2e-2ddba05f94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size_q, vocab_size_a):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,), name='encoder_input')\n",
    "    encoder_embedding = Embedding(vocab_size_q, EMBEDDING_DIM, mask_zero=True, name='encoder_embedding')\n",
    "    encoder_embed = encoder_embedding(encoder_inputs)\n",
    "    encoder_dropout = Dropout(0.2, name='encoder_dropout')(encoder_embed)\n",
    "    encoder_lstm = LSTM(LATENT_DIM, return_state=True, name='encoder_lstm')\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_dropout)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(MAX_ANSWER_LENGTH-1,), name='decoder_input')\n",
    "    decoder_embedding = Embedding(vocab_size_a, EMBEDDING_DIM, mask_zero=True, name='decoder_embedding')\n",
    "    decoder_embed = decoder_embedding(decoder_inputs)\n",
    "    decoder_dropout1 = Dropout(0.2, name='decoder_dropout1')(decoder_embed)\n",
    "    decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_dropout1, initial_state=encoder_states)\n",
    "    decoder_dropout2 = Dropout(0.2, name='decoder_dropout2')(decoder_outputs)\n",
    "    decoder_dense = Dense(vocab_size_a, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_dropout2)\n",
    "\n",
    "    # Model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(clipnorm=1.0),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dfb774-fce6-4e36-bb9f-a62ad60617cb",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb8f343d-5424-4702-bef1-e7f618b280dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_models(model, vocab_size_a):\n",
    "    # Get relevant layers from the training model\n",
    "    encoder_lstm = None\n",
    "    decoder_lstm = None\n",
    "    decoder_dense = None\n",
    "    encoder_embedding = None\n",
    "    decoder_embedding = None\n",
    "    \n",
    "    # Find the LSTM and Dense layers\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, LSTM):\n",
    "            if encoder_lstm is None:\n",
    "                encoder_lstm = layer\n",
    "            else:\n",
    "                decoder_lstm = layer\n",
    "        elif isinstance(layer, Dense):\n",
    "            decoder_dense = layer\n",
    "        elif isinstance(layer, Embedding):\n",
    "            if encoder_embedding is None:\n",
    "                encoder_embedding = layer\n",
    "            else:\n",
    "                decoder_embedding = layer\n",
    "\n",
    "    # Create encoder model\n",
    "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,))\n",
    "    x = encoder_embedding(encoder_inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    _, state_h, state_c = encoder_lstm(x)\n",
    "    encoder_model = Model(encoder_inputs, [state_h, state_c])\n",
    "\n",
    "    # Create decoder model\n",
    "    decoder_inputs = Input(shape=(1,))\n",
    "    decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "    decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "    \n",
    "    x = decoder_embedding(decoder_inputs)\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        x, \n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
    "    )\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs, decoder_state_input_h, decoder_state_input_c],\n",
    "        [decoder_outputs, state_h, state_c]\n",
    "    )\n",
    "\n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e36c8e0-12af-49e7-a514-9bd9d9606ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(encoder_model, decoder_model, q_test, a_test, answer_tokenizer):\n",
    "    smooth = SmoothingFunction().method1\n",
    "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "    \n",
    "    total_bleu = 0\n",
    "    total_rouge = 0\n",
    "    \n",
    "    for i in range(len(q_test)):\n",
    "        # Encode input sequence\n",
    "        states_value = encoder_model.predict(q_test[i:i+1], verbose=0)\n",
    "        \n",
    "        # Generate answer\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = answer_tokenizer.word_index.get('<start>', 0)\n",
    "        \n",
    "        decoded_tokens = []\n",
    "        while len(decoded_tokens) < MAX_ANSWER_LENGTH:\n",
    "            output_tokens, h, c = decoder_model.predict(\n",
    "                [target_seq] + states_value,\n",
    "                verbose=0\n",
    "            )\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = answer_tokenizer.index_word.get(sampled_token_index, '')\n",
    "            \n",
    "            if sampled_word == '<end>' or sampled_word == '':\n",
    "                break\n",
    "                \n",
    "            decoded_tokens.append(sampled_word)\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            states_value = [h, c]\n",
    "        \n",
    "        # Get reference answer\n",
    "        reference_tokens = [answer_tokenizer.index_word.get(idx, '') \n",
    "                          for idx in a_test[i] if idx != 0]\n",
    "        reference_tokens = [token for token in reference_tokens \n",
    "                          if token not in ['<start>', '<end>']]\n",
    "        \n",
    "        # Calculate BLEU score\n",
    "        bleu = sentence_bleu([reference_tokens], decoded_tokens, smoothing_function=smooth)\n",
    "        total_bleu += bleu\n",
    "        \n",
    "        # Calculate ROUGE score\n",
    "        rouge_scores = rouge_scorer_instance.score(\n",
    "            ' '.join(reference_tokens),\n",
    "            ' '.join(decoded_tokens)\n",
    "        )\n",
    "        total_rouge += rouge_scores['rougeL'].fmeasure\n",
    "    \n",
    "    return total_bleu/len(q_test), total_rouge/len(q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a18c5-b856-4e40-85cb-5cbe6f0fc27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = load_data(\"dataset\")\n",
    "q_data, a_data, q_tokenizer, a_tokenizer = preprocess_data(df)\n",
    "    \n",
    "# Split data\n",
    "indices = np.arange(len(q_data))\n",
    "np.random.shuffle(indices)\n",
    "q_data = q_data[indices]\n",
    "a_data = a_data[indices]\n",
    "    \n",
    "num_val = int(len(q_data) * VALIDATION_SPLIT)\n",
    "num_test = int(len(q_data) * TEST_SPLIT)\n",
    "    \n",
    "q_train = q_data[:-num_val-num_test]\n",
    "a_train = a_data[:-num_val-num_test]\n",
    "q_val = q_data[-num_val-num_test:-num_test]\n",
    "a_val = a_data[-num_val-num_test:-num_test]\n",
    "q_test = q_data[-num_test:]\n",
    "a_test = a_data[-num_test:]\n",
    "    \n",
    "# Build and train model\n",
    "model = build_model(len(q_tokenizer.word_index) + 1, len(a_tokenizer.word_index) + 1)\n",
    "    \n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
    "]\n",
    "    \n",
    "history = model.fit(\n",
    "    [q_train, a_train[:, :-1]], a_train[:, 1:],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=([q_val, a_val[:, :-1]], a_val[:, 1:]),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "    \n",
    "# Create inference models\n",
    "encoder_model, decoder_model = create_inference_models(\n",
    "    model, \n",
    "    len(a_tokenizer.word_index) + 1\n",
    ")\n",
    "    \n",
    "# Evaluate\n",
    "bleu_score, rouge_score = evaluate_model(\n",
    "    encoder_model, \n",
    "    decoder_model, \n",
    "    q_test, \n",
    "    a_test, \n",
    "    a_tokenizer\n",
    ")\n",
    "    \n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "print(f\"ROUGE Score: {rouge_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452ea0fc-e210-4788-bea9-1fdc90f0e792",
   "metadata": {},
   "source": [
    "## Testing on Random questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35f5eb45-13ca-45ee-baed-8c97338884db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, encoder_model, decoder_model, q_tokenizer, a_tokenizer, max_length=50):\n",
    "    # Preprocess the question\n",
    "    # Clean text (same as training)\n",
    "    question = question.lower().strip()\n",
    "    question = re.sub(r'[^a-zA-Z0-9.,!?\\'\"]', ' ', question)\n",
    "    question = re.sub(r'\\s+', ' ', question)\n",
    "    question = f\"<START> {question} <END>\"\n",
    "    \n",
    "    # Tokenize and pad the question\n",
    "    q_seq = q_tokenizer.texts_to_sequences([question])\n",
    "    q_seq = pad_sequences(q_seq, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
    "    \n",
    "    # Encode the input sequence\n",
    "    states_value = encoder_model.predict(q_seq, verbose=0)\n",
    "    \n",
    "    # Generate answer tokens\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = a_tokenizer.word_index.get('<start>', 0)\n",
    "    \n",
    "    # Collect decoded tokens\n",
    "    decoded_tokens = []\n",
    "    \n",
    "    while len(decoded_tokens) < max_length:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = a_tokenizer.index_word.get(sampled_token_index, '')\n",
    "        \n",
    "        if sampled_word == '<end>' or sampled_word == '':\n",
    "            break\n",
    "            \n",
    "        decoded_tokens.append(sampled_word)\n",
    "        \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return ' '.join(decoded_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f69ea3d0-3237-4c0a-b046-1e469fc8ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_question(df, encoder_model, decoder_model, q_tokenizer, a_tokenizer):\n",
    "    # Select random question\n",
    "    idx = np.random.randint(0, len(df))\n",
    "    original_q = df.iloc[idx]['question']\n",
    "    original_a = df.iloc[idx]['answer']\n",
    "    \n",
    "    # Get model's answer\n",
    "    model_answer = ask_question(original_q, encoder_model, decoder_model, q_tokenizer, a_tokenizer)\n",
    "    \n",
    "    print(\"Question:\", original_q)\n",
    "    print(\"Original Answer:\", original_a)\n",
    "    print(\"Model Answer:\", model_answer)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0284a0-39cf-46c3-a454-dc73fb972a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_random_question(df, encoder_model, decoder_model, q_tokenizer, a_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2ad28-5c95-4a14-ba80-5a75b769435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Answer:\", ask_question(\"What is your question?\", encoder_model, decoder_model, q_tokenizer, a_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c791d49-4848-443a-8c9c-60af2c0f5f1e",
   "metadata": {},
   "source": [
    "# Tuned LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865d448a-c998-4eb3-9f55-16770f4c79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUESTION_LENGTH = 50\n",
    "MAX_ANSWER_LENGTH = 100\n",
    "EMBEDDING_DIM = 256  # Increased from 256\n",
    "LATENT_DIM = 512    # Increased from 512\n",
    "BATCH_SIZE = 64     # Increased from 32\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "LEARNING_RATE = 3e-4\n",
    "CLIP_NORM = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abd9a3-e75b-4156-bd0d-1e0a9b884a81",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec0d6b37-f209-45de-a3cf-47babeff7ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(question, answer):\n",
    "    augmented_pairs = []\n",
    "    # Original pair\n",
    "    augmented_pairs.append((question, answer))\n",
    "    \n",
    "    # Remove punctuation version\n",
    "    q_no_punct = re.sub(r'[.,!?]', '', question)\n",
    "    augmented_pairs.append((q_no_punct, answer))\n",
    "    \n",
    "    # Shuffle words slightly (maintaining rough meaning)\n",
    "    words = question.split()\n",
    "    if len(words) > 3:\n",
    "        for i in range(min(3, len(words)-1)):\n",
    "            shuffled = words.copy()\n",
    "            shuffled[i], shuffled[i+1] = shuffled[i+1], shuffled[i]\n",
    "            augmented_pairs.append((' '.join(shuffled), answer))\n",
    "    \n",
    "    return augmented_pairs\n",
    "\n",
    "# Modify your data loading:\n",
    "def load_data(dataset_path):\n",
    "    data = []\n",
    "    for file in sorted(os.listdir(dataset_path)):\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(dataset_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                content = json.load(f)\n",
    "                qa_pairs = content.get(\"qa_pairs\", [])\n",
    "                for pair in qa_pairs:\n",
    "                    augmented = augment_data(pair[\"question\"], pair[\"answer\"])\n",
    "                    for q, a in augmented:\n",
    "                        data.append({\"question\": q, \"answer\": a})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def improved_clean_text(text):\n",
    "    \"\"\"Enhanced text cleaning with better special character handling\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    # Preserve more meaningful punctuation and symbols\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"-:;$%#@&*()]', ' ', text)\n",
    "    # Normalize numbers\n",
    "    text = re.sub(r'\\d+', 'NUM', text)\n",
    "    # Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return f\"<START> {text} <END>\"\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Improved data preprocessing\"\"\"\n",
    "    # Clean text\n",
    "    df[\"question\"] = df[\"question\"].apply(improved_clean_text)\n",
    "    df[\"answer\"] = df[\"answer\"].apply(improved_clean_text)\n",
    "    \n",
    "    # Create tokenizers with additional special tokens\n",
    "    question_tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='')\n",
    "    answer_tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='')\n",
    "    \n",
    "    # Add padding token\n",
    "    question_tokenizer.word_index['<PAD>'] = 0\n",
    "    answer_tokenizer.word_index['<PAD>'] = 0\n",
    "    \n",
    "    # Fit tokenizers\n",
    "    question_tokenizer.fit_on_texts(df[\"question\"])\n",
    "    answer_tokenizer.fit_on_texts(df[\"answer\"])\n",
    "    \n",
    "    # Convert to sequences\n",
    "    question_sequences = question_tokenizer.texts_to_sequences(df[\"question\"])\n",
    "    answer_sequences = answer_tokenizer.texts_to_sequences(df[\"answer\"])\n",
    "    \n",
    "    # Pad sequences\n",
    "    question_padded = pad_sequences(question_sequences, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
    "    answer_padded = pad_sequences(answer_sequences, maxlen=MAX_ANSWER_LENGTH, padding='post')\n",
    "    \n",
    "    return question_padded, answer_padded, question_tokenizer, answer_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dea60f-dee1-4405-9aed-7fd51385ec2a",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e731594-6ab9-4342-8c06-a65dace1f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_improved_model(vocab_size_q, vocab_size_a):\n",
    "    \"\"\"Build improved seq2seq model with optimized architecture\"\"\"\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,), name='encoder_input')\n",
    "    \n",
    "    # Improved embedding with proper initialization\n",
    "    encoder_embedding = Embedding(\n",
    "        vocab_size_q, \n",
    "        EMBEDDING_DIM,\n",
    "        mask_zero=True,\n",
    "        embeddings_initializer='glorot_uniform',\n",
    "        name='encoder_embedding'\n",
    "    )\n",
    "    encoder_embed = encoder_embedding(encoder_inputs)\n",
    "    \n",
    "    # Increase dropout rate\n",
    "    encoder_dropout1 = Dropout(0.5)(encoder_embed)  # from 0.3 to 0.5\n",
    "    \n",
    "    # Add L2 regularization to LSTM layers\n",
    "    encoder_lstm = LSTM(\n",
    "        LATENT_DIM,\n",
    "        return_state=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        recurrent_initializer='orthogonal',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        recurrent_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        name='encoder_lstm'\n",
    "    )\n",
    "    \n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_dropout1)\n",
    "    \n",
    "    # Add layer normalization\n",
    "    state_h = LayerNormalization()(state_h)\n",
    "    state_c = LayerNormalization()(state_c)\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(MAX_ANSWER_LENGTH-1,), name='decoder_input')\n",
    "    \n",
    "    decoder_embedding = Embedding(\n",
    "        vocab_size_a,\n",
    "        EMBEDDING_DIM,\n",
    "        mask_zero=True,\n",
    "        embeddings_initializer='glorot_uniform',\n",
    "        name='decoder_embedding'\n",
    "    )\n",
    "    decoder_embed = decoder_embedding(decoder_inputs)\n",
    "    \n",
    "    # Add dropout\n",
    "    decoder_dropout1 = Dropout(0.5)(decoder_embed)  # from 0.3 to 0.5\n",
    "    \n",
    "    decoder_lstm = LSTM(\n",
    "        LATENT_DIM,\n",
    "        return_sequences=True,\n",
    "        return_state=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        recurrent_initializer='orthogonal',\n",
    "        name='decoder_lstm'\n",
    "    )\n",
    "    \n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_dropout1, initial_state=[state_h, state_c])\n",
    "    \n",
    "    # Add layer normalization\n",
    "    decoder_outputs = LayerNormalization()(decoder_outputs)\n",
    "    \n",
    "    # Final dropout before dense layer\n",
    "    decoder_dropout2 = Dropout(0.5)(decoder_outputs)  # from 0.3 to 0.5\n",
    "    \n",
    "    # Dense layer with proper initialization\n",
    "    decoder_dense = Dense(\n",
    "        vocab_size_a,\n",
    "        activation='softmax',\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        name='decoder_dense'\n",
    "    )\n",
    "    decoder_outputs = decoder_dense(decoder_dropout2)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    # Custom Adam optimizer with gradient clipping\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        clipnorm=CLIP_NORM,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "    )\n",
    "\n",
    "    def sparse_categorical_crossentropy_with_smoothing(y_true, y_pred, smoothing=0.1):\n",
    "        num_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true_one_hot = tf.one_hot(y_true, tf.shape(y_pred)[-1])\n",
    "        \n",
    "        # Apply label smoothing\n",
    "        y_true_smooth = (1.0 - smoothing) * y_true_one_hot + smoothing / num_classes\n",
    "        \n",
    "        return tf.reduce_mean(\n",
    "            tf.reduce_sum(-y_true_smooth * tf.math.log(y_pred + 1e-7), axis=-1)\n",
    "        )\n",
    "\n",
    "    # Then in the model.compile():\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=sparse_categorical_crossentropy_with_smoothing,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2baa087-00e5-4ee7-b7ad-6ea656ecfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_models(model, vocab_size_a):\n",
    "    \"\"\"Create separate encoder and decoder models for inference\"\"\"\n",
    "    # Get relevant layers\n",
    "    encoder_lstm = None\n",
    "    decoder_lstm = None\n",
    "    decoder_dense = None\n",
    "    encoder_embedding = None\n",
    "    decoder_embedding = None\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, LSTM):\n",
    "            if encoder_lstm is None:\n",
    "                encoder_lstm = layer\n",
    "            else:\n",
    "                decoder_lstm = layer\n",
    "        elif isinstance(layer, Dense):\n",
    "            decoder_dense = layer\n",
    "        elif isinstance(layer, Embedding):\n",
    "            if encoder_embedding is None:\n",
    "                encoder_embedding = layer\n",
    "            else:\n",
    "                decoder_embedding = layer\n",
    "\n",
    "    # Create encoder model\n",
    "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,))\n",
    "    x = encoder_embedding(encoder_inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    _, state_h, state_c = encoder_lstm(x)\n",
    "    state_h = LayerNormalization()(state_h)\n",
    "    state_c = LayerNormalization()(state_c)\n",
    "    encoder_model = Model(encoder_inputs, [state_h, state_c])\n",
    "\n",
    "    # Create decoder model\n",
    "    decoder_inputs = Input(shape=(1,))\n",
    "    decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
    "    decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
    "    \n",
    "    x = decoder_embedding(decoder_inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        x, \n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
    "    )\n",
    "    decoder_outputs = LayerNormalization()(decoder_outputs)\n",
    "    decoder_outputs = Dropout(0.3)(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs, decoder_state_input_h, decoder_state_input_c],\n",
    "        [decoder_outputs, state_h, state_c]\n",
    "    )\n",
    "\n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb51e14-19f6-4799-af04-bdce5083bde2",
   "metadata": {},
   "source": [
    "## Model Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3cacbb6-d67f-4aea-ba05-ab353adb3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(encoder_model, decoder_model, q_test, a_test, answer_tokenizer):\n",
    "    \"\"\"Evaluate the model using BLEU and ROUGE scores\"\"\"\n",
    "    smooth = SmoothingFunction().method1\n",
    "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
    "    \n",
    "    total_bleu = 0\n",
    "    total_rouge = 0\n",
    "    \n",
    "    for i in range(len(q_test)):\n",
    "        states_value = encoder_model.predict(q_test[i:i+1], verbose=0)\n",
    "        \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = answer_tokenizer.word_index.get('<start>', 0)\n",
    "        \n",
    "        decoded_tokens = []\n",
    "        while len(decoded_tokens) < MAX_ANSWER_LENGTH:\n",
    "            output_tokens, h, c = decoder_model.predict(\n",
    "                [target_seq] + states_value,\n",
    "                verbose=0\n",
    "            )\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = answer_tokenizer.index_word.get(sampled_token_index, '')\n",
    "            \n",
    "            if sampled_word == '<end>' or sampled_word == '':\n",
    "                break\n",
    "                \n",
    "            decoded_tokens.append(sampled_word)\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            states_value = [h, c]\n",
    "        \n",
    "        reference_tokens = [answer_tokenizer.index_word.get(idx, '') \n",
    "                          for idx in a_test[i] if idx != 0]\n",
    "        reference_tokens = [token for token in reference_tokens \n",
    "                          if token not in ['<start>', '<end>', '<pad>']]\n",
    "        \n",
    "        bleu = sentence_bleu([reference_tokens], decoded_tokens, smoothing_function=smooth)\n",
    "        total_bleu += bleu\n",
    "        \n",
    "        rouge_scores = rouge_scorer_instance.score(\n",
    "            ' '.join(reference_tokens),\n",
    "            ' '.join(decoded_tokens)\n",
    "        )\n",
    "        total_rouge += rouge_scores['rougeL'].fmeasure\n",
    "    \n",
    "    return total_bleu/len(q_test), total_rouge/len(q_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bbdd9a2-81e2-4e39-9f89-1eaf43f20262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, encoder_model, decoder_model, q_tokenizer, a_tokenizer, max_length=50):\n",
    "    \"\"\"Ask a question to the trained model and get its response\"\"\"\n",
    "    question = improved_clean_text(question)\n",
    "    \n",
    "    q_seq = q_tokenizer.texts_to_sequences([question])\n",
    "    q_seq = pad_sequences(q_seq, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
    "    \n",
    "    states_value = encoder_model.predict(q_seq, verbose=0)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = a_tokenizer.word_index.get('<start>', 0)\n",
    "    \n",
    "    decoded_tokens = []\n",
    "    \n",
    "    while len(decoded_tokens) < max_length:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = a_tokenizer.index_word.get(sampled_token_index, '')\n",
    "        \n",
    "        if sampled_word == '<end>' or sampled_word == '':\n",
    "            break\n",
    "            \n",
    "        decoded_tokens.append(sampled_word)\n",
    "        \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return ' '.join(decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27bbe5-3efc-479d-9b70-8571d2ec1bf1",
   "metadata": {},
   "source": [
    "## Training and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf62dfb-f600-47a2-afe6-e338c056168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, warmup_steps, initial_lr):\n",
    "        super().__init__()\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.initial_lr = initial_lr\n",
    "        self.step = 0\n",
    "        \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        self.step += 1\n",
    "        if self.step <= self.warmup_steps:\n",
    "            lr = (self.step / self.warmup_steps) * self.initial_lr\n",
    "            self.model.optimizer.learning_rate.assign(lr)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=1e-4\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=12,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "callbacks.append(WarmUpLearningRateScheduler(warmup_steps=100, initial_lr=5e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2a4d535-5fe1-4d71-99e5-e8909766dd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">346,624</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,620,992</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]        │                 │ not_equal_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_24        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]        │                 │ layer_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ layer_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6332</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,248,316</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m346,624\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ encoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_16 (\u001b[38;5;33mNotEqual\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,620,992\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │       \u001b[38;5;34m1,574,912\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]        │                 │ not_equal_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ decoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_24        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │       \u001b[38;5;34m1,574,912\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]        │                 │ layer_normalization_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ layer_normalization_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m6332\u001b[0m)          │       \u001b[38;5;34m3,248,316\u001b[0m │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,368,828</span> (31.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,368,828\u001b[0m (31.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,368,828</span> (31.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,368,828\u001b[0m (31.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.2187 - loss: 7.2295      \n",
      "Epoch 1: val_loss improved from inf to 5.25599, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 788ms/step - accuracy: 0.2192 - loss: 7.2234 - val_accuracy: 0.3521 - val_loss: 5.2560 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - accuracy: 0.3494 - loss: 5.1978  \n",
      "Epoch 2: val_loss improved from 5.25599 to 4.56926, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 770ms/step - accuracy: 0.3495 - loss: 5.1968 - val_accuracy: 0.4037 - val_loss: 4.5693 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.3993 - loss: 4.5216  \n",
      "Epoch 3: val_loss improved from 4.56926 to 4.01193, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 708ms/step - accuracy: 0.3994 - loss: 4.5210 - val_accuracy: 0.4527 - val_loss: 4.0119 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - accuracy: 0.4412 - loss: 4.0072  \n",
      "Epoch 4: val_loss improved from 4.01193 to 3.52942, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 670ms/step - accuracy: 0.4412 - loss: 4.0065 - val_accuracy: 0.5077 - val_loss: 3.5294 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.5054 - loss: 3.5012  \n",
      "Epoch 5: val_loss improved from 3.52942 to 3.08589, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 648ms/step - accuracy: 0.5054 - loss: 3.5008 - val_accuracy: 0.5798 - val_loss: 3.0859 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step - accuracy: 0.5721 - loss: 3.1047  \n",
      "Epoch 6: val_loss improved from 3.08589 to 2.73003, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 664ms/step - accuracy: 0.5721 - loss: 3.1045 - val_accuracy: 0.6539 - val_loss: 2.7300 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.6245 - loss: 2.8424  \n",
      "Epoch 7: val_loss improved from 2.73003 to 2.45103, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.6246 - loss: 2.8421 - val_accuracy: 0.7197 - val_loss: 2.4510 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step - accuracy: 0.6761 - loss: 2.6095  \n",
      "Epoch 8: val_loss improved from 2.45103 to 2.23562, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 647ms/step - accuracy: 0.6762 - loss: 2.6093 - val_accuracy: 0.7759 - val_loss: 2.2356 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.7150 - loss: 2.4371  \n",
      "Epoch 9: val_loss improved from 2.23562 to 2.07153, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 648ms/step - accuracy: 0.7151 - loss: 2.4370 - val_accuracy: 0.8198 - val_loss: 2.0715 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.7487 - loss: 2.3050  \n",
      "Epoch 10: val_loss improved from 2.07153 to 1.95191, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 660ms/step - accuracy: 0.7487 - loss: 2.3050 - val_accuracy: 0.8539 - val_loss: 1.9519 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638ms/step - accuracy: 0.7706 - loss: 2.2145  \n",
      "Epoch 11: val_loss improved from 1.95191 to 1.86102, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 658ms/step - accuracy: 0.7706 - loss: 2.2144 - val_accuracy: 0.8792 - val_loss: 1.8610 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.7916 - loss: 2.1312  \n",
      "Epoch 12: val_loss improved from 1.86102 to 1.78637, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.7916 - loss: 2.1312 - val_accuracy: 0.9009 - val_loss: 1.7864 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step - accuracy: 0.8069 - loss: 2.0803  \n",
      "Epoch 13: val_loss improved from 1.78637 to 1.73416, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 655ms/step - accuracy: 0.8069 - loss: 2.0802 - val_accuracy: 0.9174 - val_loss: 1.7342 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - accuracy: 0.8228 - loss: 2.0253  \n",
      "Epoch 14: val_loss improved from 1.73416 to 1.68225, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 655ms/step - accuracy: 0.8228 - loss: 2.0252 - val_accuracy: 0.9306 - val_loss: 1.6822 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.8349 - loss: 1.9786  \n",
      "Epoch 15: val_loss improved from 1.68225 to 1.65392, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.8349 - loss: 1.9786 - val_accuracy: 0.9416 - val_loss: 1.6539 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.8462 - loss: 1.9382  \n",
      "Epoch 16: val_loss improved from 1.65392 to 1.61926, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 648ms/step - accuracy: 0.8462 - loss: 1.9382 - val_accuracy: 0.9499 - val_loss: 1.6193 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.8586 - loss: 1.9007  \n",
      "Epoch 17: val_loss improved from 1.61926 to 1.59368, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.8586 - loss: 1.9007 - val_accuracy: 0.9590 - val_loss: 1.5937 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637ms/step - accuracy: 0.8673 - loss: 1.8653  \n",
      "Epoch 18: val_loss improved from 1.59368 to 1.56948, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 657ms/step - accuracy: 0.8673 - loss: 1.8654 - val_accuracy: 0.9665 - val_loss: 1.5695 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step - accuracy: 0.8702 - loss: 1.8595  \n",
      "Epoch 19: val_loss improved from 1.56948 to 1.55768, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 876ms/step - accuracy: 0.8703 - loss: 1.8594 - val_accuracy: 0.9685 - val_loss: 1.5577 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.8774 - loss: 1.8283  \n",
      "Epoch 20: val_loss improved from 1.55768 to 1.53821, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 673ms/step - accuracy: 0.8774 - loss: 1.8283 - val_accuracy: 0.9747 - val_loss: 1.5382 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679ms/step - accuracy: 0.8854 - loss: 1.8064  \n",
      "Epoch 21: val_loss improved from 1.53821 to 1.52299, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 700ms/step - accuracy: 0.8854 - loss: 1.8064 - val_accuracy: 0.9781 - val_loss: 1.5230 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.8921 - loss: 1.7810  \n",
      "Epoch 22: val_loss improved from 1.52299 to 1.51604, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 682ms/step - accuracy: 0.8921 - loss: 1.7811 - val_accuracy: 0.9799 - val_loss: 1.5160 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - accuracy: 0.8973 - loss: 1.7625  \n",
      "Epoch 23: val_loss improved from 1.51604 to 1.50748, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 677ms/step - accuracy: 0.8973 - loss: 1.7625 - val_accuracy: 0.9814 - val_loss: 1.5075 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.9028 - loss: 1.7482  \n",
      "Epoch 24: val_loss improved from 1.50748 to 1.49614, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 684ms/step - accuracy: 0.9028 - loss: 1.7482 - val_accuracy: 0.9830 - val_loss: 1.4961 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.9062 - loss: 1.7353  \n",
      "Epoch 25: val_loss improved from 1.49614 to 1.48565, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 694ms/step - accuracy: 0.9062 - loss: 1.7353 - val_accuracy: 0.9866 - val_loss: 1.4856 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - accuracy: 0.9116 - loss: 1.7189  \n",
      "Epoch 26: val_loss improved from 1.48565 to 1.48167, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 669ms/step - accuracy: 0.9116 - loss: 1.7190 - val_accuracy: 0.9862 - val_loss: 1.4817 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.9143 - loss: 1.7033  \n",
      "Epoch 27: val_loss improved from 1.48167 to 1.47332, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 672ms/step - accuracy: 0.9143 - loss: 1.7033 - val_accuracy: 0.9884 - val_loss: 1.4733 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.9185 - loss: 1.6911  \n",
      "Epoch 28: val_loss improved from 1.47332 to 1.46403, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 737ms/step - accuracy: 0.9185 - loss: 1.6911 - val_accuracy: 0.9907 - val_loss: 1.4640 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.9225 - loss: 1.6794  \n",
      "Epoch 29: val_loss improved from 1.46403 to 1.45908, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 733ms/step - accuracy: 0.9225 - loss: 1.6794 - val_accuracy: 0.9907 - val_loss: 1.4591 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - accuracy: 0.9249 - loss: 1.6689  \n",
      "Epoch 30: val_loss improved from 1.45908 to 1.45507, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 722ms/step - accuracy: 0.9249 - loss: 1.6689 - val_accuracy: 0.9916 - val_loss: 1.4551 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.9281 - loss: 1.6573  \n",
      "Epoch 31: val_loss improved from 1.45507 to 1.44926, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 714ms/step - accuracy: 0.9281 - loss: 1.6573 - val_accuracy: 0.9931 - val_loss: 1.4493 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - accuracy: 0.9309 - loss: 1.6471  \n",
      "Epoch 32: val_loss improved from 1.44926 to 1.44222, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 736ms/step - accuracy: 0.9309 - loss: 1.6471 - val_accuracy: 0.9933 - val_loss: 1.4422 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687ms/step - accuracy: 0.9342 - loss: 1.6354  \n",
      "Epoch 33: val_loss improved from 1.44222 to 1.44108, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 708ms/step - accuracy: 0.9342 - loss: 1.6354 - val_accuracy: 0.9936 - val_loss: 1.4411 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.9378 - loss: 1.6255  \n",
      "Epoch 34: val_loss improved from 1.44108 to 1.43614, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 769ms/step - accuracy: 0.9378 - loss: 1.6255 - val_accuracy: 0.9945 - val_loss: 1.4361 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.9393 - loss: 1.6190  \n",
      "Epoch 35: val_loss improved from 1.43614 to 1.43241, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 684ms/step - accuracy: 0.9393 - loss: 1.6190 - val_accuracy: 0.9951 - val_loss: 1.4324 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.9413 - loss: 1.6121  \n",
      "Epoch 36: val_loss improved from 1.43241 to 1.42804, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 729ms/step - accuracy: 0.9412 - loss: 1.6121 - val_accuracy: 0.9959 - val_loss: 1.4280 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.9447 - loss: 1.6012  \n",
      "Epoch 37: val_loss improved from 1.42804 to 1.42408, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 802ms/step - accuracy: 0.9447 - loss: 1.6012 - val_accuracy: 0.9961 - val_loss: 1.4241 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.9470 - loss: 1.5943  \n",
      "Epoch 38: val_loss improved from 1.42408 to 1.42228, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 728ms/step - accuracy: 0.9470 - loss: 1.5943 - val_accuracy: 0.9965 - val_loss: 1.4223 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658ms/step - accuracy: 0.9471 - loss: 1.5910  \n",
      "Epoch 39: val_loss improved from 1.42228 to 1.41961, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 679ms/step - accuracy: 0.9471 - loss: 1.5910 - val_accuracy: 0.9970 - val_loss: 1.4196 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - accuracy: 0.9486 - loss: 1.5835  \n",
      "Epoch 40: val_loss improved from 1.41961 to 1.41583, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 691ms/step - accuracy: 0.9486 - loss: 1.5835 - val_accuracy: 0.9969 - val_loss: 1.4158 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - accuracy: 0.9521 - loss: 1.5715  \n",
      "Epoch 41: val_loss improved from 1.41583 to 1.41329, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 838ms/step - accuracy: 0.9521 - loss: 1.5716 - val_accuracy: 0.9966 - val_loss: 1.4133 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883ms/step - accuracy: 0.9521 - loss: 1.5702  \n",
      "Epoch 42: val_loss improved from 1.41329 to 1.41126, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 905ms/step - accuracy: 0.9520 - loss: 1.5702 - val_accuracy: 0.9973 - val_loss: 1.4113 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.9536 - loss: 1.5652  \n",
      "Epoch 43: val_loss improved from 1.41126 to 1.40919, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 688ms/step - accuracy: 0.9536 - loss: 1.5652 - val_accuracy: 0.9976 - val_loss: 1.4092 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step - accuracy: 0.9555 - loss: 1.5604  \n",
      "Epoch 44: val_loss improved from 1.40919 to 1.40832, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 691ms/step - accuracy: 0.9555 - loss: 1.5604 - val_accuracy: 0.9977 - val_loss: 1.4083 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.9571 - loss: 1.5530  \n",
      "Epoch 45: val_loss improved from 1.40832 to 1.40532, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 738ms/step - accuracy: 0.9571 - loss: 1.5530 - val_accuracy: 0.9976 - val_loss: 1.4053 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9589 - loss: 1.5499  \n",
      "Epoch 46: val_loss improved from 1.40532 to 1.40069, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 730ms/step - accuracy: 0.9589 - loss: 1.5499 - val_accuracy: 0.9978 - val_loss: 1.4007 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - accuracy: 0.9594 - loss: 1.5458  \n",
      "Epoch 47: val_loss did not improve from 1.40069\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 722ms/step - accuracy: 0.9594 - loss: 1.5458 - val_accuracy: 0.9982 - val_loss: 1.4013 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.9614 - loss: 1.5393  \n",
      "Epoch 48: val_loss improved from 1.40069 to 1.39924, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 699ms/step - accuracy: 0.9614 - loss: 1.5393 - val_accuracy: 0.9982 - val_loss: 1.3992 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.9630 - loss: 1.5347  \n",
      "Epoch 49: val_loss improved from 1.39924 to 1.39742, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 755ms/step - accuracy: 0.9630 - loss: 1.5347 - val_accuracy: 0.9988 - val_loss: 1.3974 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step - accuracy: 0.9641 - loss: 1.5289  \n",
      "Epoch 50: val_loss did not improve from 1.39742\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 823ms/step - accuracy: 0.9641 - loss: 1.5289 - val_accuracy: 0.9985 - val_loss: 1.3979 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.9647 - loss: 1.5249  \n",
      "Epoch 51: val_loss improved from 1.39742 to 1.39463, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 721ms/step - accuracy: 0.9647 - loss: 1.5249 - val_accuracy: 0.9984 - val_loss: 1.3946 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.9654 - loss: 1.5231  \n",
      "Epoch 52: val_loss improved from 1.39463 to 1.39314, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 690ms/step - accuracy: 0.9654 - loss: 1.5231 - val_accuracy: 0.9985 - val_loss: 1.3931 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.9671 - loss: 1.5160  \n",
      "Epoch 53: val_loss improved from 1.39314 to 1.39295, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 685ms/step - accuracy: 0.9671 - loss: 1.5160 - val_accuracy: 0.9984 - val_loss: 1.3930 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674ms/step - accuracy: 0.9680 - loss: 1.5140  \n",
      "Epoch 54: val_loss improved from 1.39295 to 1.39105, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 696ms/step - accuracy: 0.9680 - loss: 1.5140 - val_accuracy: 0.9989 - val_loss: 1.3911 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - accuracy: 0.9693 - loss: 1.5080  \n",
      "Epoch 55: val_loss improved from 1.39105 to 1.39058, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 684ms/step - accuracy: 0.9693 - loss: 1.5080 - val_accuracy: 0.9982 - val_loss: 1.3906 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - accuracy: 0.9703 - loss: 1.5042  \n",
      "Epoch 56: val_loss improved from 1.39058 to 1.38827, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 687ms/step - accuracy: 0.9703 - loss: 1.5042 - val_accuracy: 0.9988 - val_loss: 1.3883 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.9713 - loss: 1.5035  \n",
      "Epoch 57: val_loss improved from 1.38827 to 1.38678, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 665ms/step - accuracy: 0.9713 - loss: 1.5035 - val_accuracy: 0.9991 - val_loss: 1.3868 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.9718 - loss: 1.4992  \n",
      "Epoch 58: val_loss improved from 1.38678 to 1.38622, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 673ms/step - accuracy: 0.9718 - loss: 1.4992 - val_accuracy: 0.9987 - val_loss: 1.3862 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.9732 - loss: 1.4973  \n",
      "Epoch 59: val_loss improved from 1.38622 to 1.38476, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 756ms/step - accuracy: 0.9732 - loss: 1.4973 - val_accuracy: 0.9988 - val_loss: 1.3848 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9729 - loss: 1.4948  \n",
      "Epoch 60: val_loss improved from 1.38476 to 1.38337, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 785ms/step - accuracy: 0.9729 - loss: 1.4948 - val_accuracy: 0.9992 - val_loss: 1.3834 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9745 - loss: 1.4895  \n",
      "Epoch 61: val_loss improved from 1.38337 to 1.38059, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 782ms/step - accuracy: 0.9745 - loss: 1.4895 - val_accuracy: 0.9992 - val_loss: 1.3806 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9758 - loss: 1.4843  \n",
      "Epoch 62: val_loss improved from 1.38059 to 1.37991, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 783ms/step - accuracy: 0.9758 - loss: 1.4844 - val_accuracy: 0.9993 - val_loss: 1.3799 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.9760 - loss: 1.4861  \n",
      "Epoch 63: val_loss improved from 1.37991 to 1.37899, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 741ms/step - accuracy: 0.9760 - loss: 1.4861 - val_accuracy: 0.9991 - val_loss: 1.3790 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.9771 - loss: 1.4793  \n",
      "Epoch 64: val_loss improved from 1.37899 to 1.37846, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 790ms/step - accuracy: 0.9771 - loss: 1.4793 - val_accuracy: 0.9992 - val_loss: 1.3785 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - accuracy: 0.9766 - loss: 1.4795  \n",
      "Epoch 65: val_loss improved from 1.37846 to 1.37707, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 796ms/step - accuracy: 0.9766 - loss: 1.4795 - val_accuracy: 0.9991 - val_loss: 1.3771 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - accuracy: 0.9778 - loss: 1.4746  \n",
      "Epoch 66: val_loss improved from 1.37707 to 1.37640, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 801ms/step - accuracy: 0.9778 - loss: 1.4746 - val_accuracy: 0.9992 - val_loss: 1.3764 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9785 - loss: 1.4718  \n",
      "Epoch 67: val_loss improved from 1.37640 to 1.37353, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 780ms/step - accuracy: 0.9785 - loss: 1.4718 - val_accuracy: 0.9992 - val_loss: 1.3735 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9796 - loss: 1.4703  \n",
      "Epoch 68: val_loss did not improve from 1.37353\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 778ms/step - accuracy: 0.9795 - loss: 1.4703 - val_accuracy: 0.9991 - val_loss: 1.3745 - learning_rate: 5.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9794 - loss: 1.4679  \n",
      "Epoch 69: val_loss did not improve from 1.37353\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 778ms/step - accuracy: 0.9794 - loss: 1.4679 - val_accuracy: 0.9991 - val_loss: 1.3745 - learning_rate: 5.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9803 - loss: 1.4658  \n",
      "Epoch 70: val_loss improved from 1.37353 to 1.37147, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 781ms/step - accuracy: 0.9803 - loss: 1.4658 - val_accuracy: 0.9993 - val_loss: 1.3715 - learning_rate: 5.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.9801 - loss: 1.4655  \n",
      "Epoch 71: val_loss did not improve from 1.37147\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 789ms/step - accuracy: 0.9801 - loss: 1.4655 - val_accuracy: 0.9992 - val_loss: 1.3723 - learning_rate: 5.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.9799 - loss: 1.4677  \n",
      "Epoch 72: val_loss improved from 1.37147 to 1.36974, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 790ms/step - accuracy: 0.9799 - loss: 1.4676 - val_accuracy: 0.9994 - val_loss: 1.3697 - learning_rate: 5.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.9817 - loss: 1.4598  \n",
      "Epoch 73: val_loss improved from 1.36974 to 1.36881, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 774ms/step - accuracy: 0.9817 - loss: 1.4598 - val_accuracy: 0.9993 - val_loss: 1.3688 - learning_rate: 5.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.9826 - loss: 1.4572  \n",
      "Epoch 74: val_loss improved from 1.36881 to 1.36746, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 778ms/step - accuracy: 0.9826 - loss: 1.4572 - val_accuracy: 0.9992 - val_loss: 1.3675 - learning_rate: 5.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - accuracy: 0.9817 - loss: 1.4580  \n",
      "Epoch 75: val_loss did not improve from 1.36746\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 770ms/step - accuracy: 0.9817 - loss: 1.4580 - val_accuracy: 0.9993 - val_loss: 1.3686 - learning_rate: 5.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.9829 - loss: 1.4565  \n",
      "Epoch 76: val_loss did not improve from 1.36746\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 773ms/step - accuracy: 0.9829 - loss: 1.4565 - val_accuracy: 0.9993 - val_loss: 1.3677 - learning_rate: 5.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9834 - loss: 1.4534  \n",
      "Epoch 77: val_loss improved from 1.36746 to 1.36657, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 784ms/step - accuracy: 0.9834 - loss: 1.4534 - val_accuracy: 0.9993 - val_loss: 1.3666 - learning_rate: 5.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.9835 - loss: 1.4503  \n",
      "Epoch 78: val_loss improved from 1.36657 to 1.36484, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 776ms/step - accuracy: 0.9835 - loss: 1.4503 - val_accuracy: 0.9992 - val_loss: 1.3648 - learning_rate: 5.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.9848 - loss: 1.4466  \n",
      "Epoch 79: val_loss improved from 1.36484 to 1.36336, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 784ms/step - accuracy: 0.9848 - loss: 1.4466 - val_accuracy: 0.9991 - val_loss: 1.3634 - learning_rate: 5.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9846 - loss: 1.4487  \n",
      "Epoch 80: val_loss did not improve from 1.36336\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 776ms/step - accuracy: 0.9846 - loss: 1.4487 - val_accuracy: 0.9992 - val_loss: 1.3642 - learning_rate: 5.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775ms/step - accuracy: 0.9851 - loss: 1.4465  \n",
      "Epoch 81: val_loss improved from 1.36336 to 1.36223, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 802ms/step - accuracy: 0.9851 - loss: 1.4465 - val_accuracy: 0.9990 - val_loss: 1.3622 - learning_rate: 5.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9847 - loss: 1.4427     \n",
      "Epoch 82: val_loss improved from 1.36223 to 1.36206, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.9847 - loss: 1.4427 - val_accuracy: 0.9992 - val_loss: 1.3621 - learning_rate: 5.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9853 - loss: 1.4429  \n",
      "Epoch 83: val_loss improved from 1.36206 to 1.35981, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2s/step - accuracy: 0.9853 - loss: 1.4429 - val_accuracy: 0.9996 - val_loss: 1.3598 - learning_rate: 5.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9858 - loss: 1.4390  \n",
      "Epoch 84: val_loss did not improve from 1.35981\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 2s/step - accuracy: 0.9858 - loss: 1.4391 - val_accuracy: 0.9993 - val_loss: 1.3607 - learning_rate: 5.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9866 - loss: 1.4360  \n",
      "Epoch 85: val_loss did not improve from 1.35981\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9866 - loss: 1.4360 - val_accuracy: 0.9994 - val_loss: 1.3600 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 1.4376  \n",
      "Epoch 86: val_loss improved from 1.35981 to 1.35965, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 1.4376 - val_accuracy: 0.9995 - val_loss: 1.3597 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894ms/step - accuracy: 0.9874 - loss: 1.4350  \n",
      "Epoch 87: val_loss improved from 1.35965 to 1.35651, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 964ms/step - accuracy: 0.9874 - loss: 1.4350 - val_accuracy: 0.9991 - val_loss: 1.3565 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9869 - loss: 1.4344  \n",
      "Epoch 88: val_loss improved from 1.35651 to 1.35620, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 1s/step - accuracy: 0.9869 - loss: 1.4344 - val_accuracy: 0.9993 - val_loss: 1.3562 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 1.4327  \n",
      "Epoch 89: val_loss did not improve from 1.35620\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 1.4327 - val_accuracy: 0.9993 - val_loss: 1.3582 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9882 - loss: 1.4289  \n",
      "Epoch 90: val_loss improved from 1.35620 to 1.35532, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.9882 - loss: 1.4289 - val_accuracy: 0.9995 - val_loss: 1.3553 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9886 - loss: 1.4294  \n",
      "Epoch 91: val_loss did not improve from 1.35532\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - accuracy: 0.9886 - loss: 1.4294 - val_accuracy: 0.9994 - val_loss: 1.3557 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 1.4294  \n",
      "Epoch 92: val_loss improved from 1.35532 to 1.35403, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 1.4294 - val_accuracy: 0.9996 - val_loss: 1.3540 - learning_rate: 5.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9886 - loss: 1.4245  \n",
      "Epoch 93: val_loss did not improve from 1.35403\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - accuracy: 0.9886 - loss: 1.4245 - val_accuracy: 0.9993 - val_loss: 1.3549 - learning_rate: 5.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9885 - loss: 1.4274  \n",
      "Epoch 94: val_loss improved from 1.35403 to 1.35289, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9885 - loss: 1.4274 - val_accuracy: 0.9995 - val_loss: 1.3529 - learning_rate: 5.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4227  \n",
      "Epoch 95: val_loss did not improve from 1.35289\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4227 - val_accuracy: 0.9995 - val_loss: 1.3529 - learning_rate: 5.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4226  \n",
      "Epoch 96: val_loss improved from 1.35289 to 1.35004, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4226 - val_accuracy: 0.9996 - val_loss: 1.3500 - learning_rate: 5.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9893 - loss: 1.4240  \n",
      "Epoch 97: val_loss improved from 1.35004 to 1.35003, saving model to best_model.keras\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.9893 - loss: 1.4240 - val_accuracy: 0.9995 - val_loss: 1.3500 - learning_rate: 5.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 1.4201  \n",
      "Epoch 98: val_loss did not improve from 1.35003\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 1.4202 - val_accuracy: 0.9997 - val_loss: 1.3522 - learning_rate: 5.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4178  \n",
      "Epoch 99: val_loss did not improve from 1.35003\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4178 - val_accuracy: 0.9994 - val_loss: 1.3514 - learning_rate: 5.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4181  \n",
      "Epoch 100: val_loss did not improve from 1.35003\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4181 - val_accuracy: 0.9994 - val_loss: 1.3503 - learning_rate: 5.0000e-04\n",
      "\n",
      "Evaluation Results:\n",
      "BLEU Score: 0.9533\n",
      "ROUGE Score: 0.9635\n"
     ]
    }
   ],
   "source": [
    "df = load_data(\"dataset\")\n",
    "q_data, a_data, q_tokenizer, a_tokenizer = preprocess_data(df)\n",
    "    \n",
    "# Split data\n",
    "indices = np.arange(len(q_data))\n",
    "np.random.shuffle(indices)\n",
    "q_data = q_data[indices]\n",
    "a_data = a_data[indices]\n",
    "    \n",
    "num_val = int(len(q_data) * VALIDATION_SPLIT)\n",
    "num_test = int(len(q_data) * TEST_SPLIT)\n",
    "    \n",
    "q_train = q_data[:-num_val-num_test]\n",
    "a_train = a_data[:-num_val-num_test]\n",
    "q_val = q_data[-num_val-num_test:-num_test]\n",
    "a_val = a_data[-num_val-num_test:-num_test]\n",
    "q_test = q_data[-num_test:]\n",
    "a_test = a_data[-num_test:]\n",
    "    \n",
    "# Build and train model\n",
    "model = build_improved_model(len(q_tokenizer.word_index) + 1, len(a_tokenizer.word_index) + 1)\n",
    "    \n",
    "history = model.fit(\n",
    "    [q_train, a_train[:, :-1]],\n",
    "    a_train[:, 1:],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=([q_val, a_val[:, :-1]], a_val[:, 1:]),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Create inference models\n",
    "encoder_model, decoder_model = create_inference_models(model, len(a_tokenizer.word_index) + 1)\n",
    "    \n",
    "# Evaluate\n",
    "bleu_score, rouge_score = evaluate_model(encoder_model, decoder_model, q_test, a_test, a_tokenizer)\n",
    "    \n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "print(f\"ROUGE Score: {rouge_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fafa927-ff7a-40a9-b354-e0be76276aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: blockchain is a decentralized digital currency that operates without a central authority or banks. it enables peer-to-peer transactions on a global scale through a network of computers running the bitcoin protocol. transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain. bitcoin\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", ask_question(\"what is blockchain ?\", encoder_model, decoder_model, q_tokenizer, a_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190debc0-d689-432d-9bbf-44a497eaaedd",
   "metadata": {},
   "source": [
    "# Final Tuned LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b792c5b-bb43-432c-a168-8c435c85623a",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e0975c0-ad56-41cd-a7d2-b41c677c4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_augment_data(question, answer, augmentation_factor=3):\n",
    "    augmented_pairs = [(question, answer)] \n",
    "    \n",
    "    translator = Translator()\n",
    "    \n",
    "    def get_synonyms(word):\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() != word and '_' not in lemma.name():\n",
    "                    synonyms.append(lemma.name())\n",
    "        return list(set(synonyms))\n",
    "    \n",
    "    def back_translate(text, intermediate_langs=['fr', 'de', 'es']):\n",
    "        try:\n",
    "            lang = random.choice(intermediate_langs)\n",
    "            intermediate = translator.translate(text, dest=lang).text\n",
    "            return translator.translate(intermediate, dest='en').text\n",
    "        except:\n",
    "            return text\n",
    "    \n",
    "    # 1. Synonym replacement\n",
    "    words = question.split()\n",
    "    for _ in range(min(3, len(words))):\n",
    "        new_words = words.copy()\n",
    "        idx = random.randint(0, len(words)-1)\n",
    "        synonyms = get_synonyms(words[idx])\n",
    "        if synonyms:\n",
    "            new_words[idx] = random.choice(synonyms)\n",
    "            augmented_pairs.append((' '.join(new_words), answer))\n",
    "    \n",
    "    # 2. Back translation\n",
    "    if len(question.split()) > 3:  # Only for longer questions\n",
    "        translated = back_translate(question)\n",
    "        if translated != question:\n",
    "            augmented_pairs.append((translated, answer))\n",
    "    \n",
    "    # 3. Random deletion (with probability)\n",
    "    if len(words) > 4:\n",
    "        new_words = [word for word in words if random.random() > 0.2]\n",
    "        if new_words:\n",
    "            augmented_pairs.append((' '.join(new_words), answer))\n",
    "    \n",
    "    return augmented_pairs[:augmentation_factor] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471e670-c0d3-484e-9f02-bca3662af383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (block-query)",
   "language": "python",
   "name": "block-query"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
