{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7cf8237b-d50a-4dc9-a294-2bb422847ce0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "7cf8237b-d50a-4dc9-a294-2bb422847ce0",
        "outputId": "9e3c273c-b91b-44ca-a392-78ca0b195d5b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'rouge_score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-88bbd519ac36>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrouge_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogletrans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge_score'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    LSTM,\n",
        "    Dense,\n",
        "    Embedding,\n",
        "    Dropout,\n",
        "    TimeDistributed,\n",
        "    Masking,\n",
        "    LayerNormalization,\n",
        "    Concatenate\n",
        ")\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ReduceLROnPlateau,\n",
        "    ModelCheckpoint\n",
        ")\n",
        "\n",
        "from nltk.translate.bleu_score import (\n",
        "    sentence_bleu,\n",
        "    SmoothingFunction,\n",
        "    corpus_bleu\n",
        ")\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.corpus import wordnet\n",
        "from googletrans import Translator\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c791d49-4848-443a-8c9c-60af2c0f5f1e",
      "metadata": {
        "id": "7c791d49-4848-443a-8c9c-60af2c0f5f1e",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Basic LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865d448a-c998-4eb3-9f55-16770f4c79ef",
      "metadata": {
        "id": "865d448a-c998-4eb3-9f55-16770f4c79ef"
      },
      "outputs": [],
      "source": [
        "MAX_QUESTION_LENGTH = 50\n",
        "MAX_ANSWER_LENGTH = 100\n",
        "EMBEDDING_DIM = 256\n",
        "LATENT_DIM = 512\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "LEARNING_RATE = 3e-4\n",
        "CLIP_NORM = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75abd9a3-e75b-4156-bd0d-1e0a9b884a81",
      "metadata": {
        "id": "75abd9a3-e75b-4156-bd0d-1e0a9b884a81"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0d6b37-f209-45de-a3cf-47babeff7ce2",
      "metadata": {
        "id": "ec0d6b37-f209-45de-a3cf-47babeff7ce2"
      },
      "outputs": [],
      "source": [
        "def augment_data(question, answer):\n",
        "    augmented_pairs = []\n",
        "    # Original pair\n",
        "    augmented_pairs.append((question, answer))\n",
        "\n",
        "    # Remove punctuation version\n",
        "    q_no_punct = re.sub(r'[.,!?]', '', question)\n",
        "    augmented_pairs.append((q_no_punct, answer))\n",
        "\n",
        "    # Shuffle words\n",
        "    words = question.split()\n",
        "    if len(words) > 3:\n",
        "        for i in range(min(3, len(words)-1)):\n",
        "            shuffled = words.copy()\n",
        "            shuffled[i], shuffled[i+1] = shuffled[i+1], shuffled[i]\n",
        "            augmented_pairs.append((' '.join(shuffled), answer))\n",
        "\n",
        "    return augmented_pairs\n",
        "\n",
        "def load_data(dataset_path):\n",
        "    data = []\n",
        "    for file in sorted(os.listdir(dataset_path)):\n",
        "        if file.endswith(\".json\"):\n",
        "            with open(os.path.join(dataset_path, file), \"r\", encoding=\"utf-8\") as f:\n",
        "                content = json.load(f)\n",
        "                qa_pairs = content.get(\"qa_pairs\", [])\n",
        "                for pair in qa_pairs:\n",
        "                    augmented = augment_data(pair[\"question\"], pair[\"answer\"])\n",
        "                    for q, a in augmented:\n",
        "                        data.append({\"question\": q, \"answer\": a})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def improved_clean_text(text):\n",
        "    text = text.lower().strip()\n",
        "    # Preserve more meaningful punctuation and symbols\n",
        "    text = re.sub(r'[^\\w\\s.,!?\\'\"-:;$%#@&*()]', ' ', text)\n",
        "    # Normalize numbers\n",
        "    text = re.sub(r'\\d+', 'NUM', text)\n",
        "    # Normalize spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return f\"<START> {text} <END>\"\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df[\"question\"] = df[\"question\"].apply(improved_clean_text)\n",
        "    df[\"answer\"] = df[\"answer\"].apply(improved_clean_text)\n",
        "\n",
        "    # Create tokenizers with additional special tokens\n",
        "    question_tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='')\n",
        "    answer_tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='')\n",
        "\n",
        "    # Add padding token\n",
        "    question_tokenizer.word_index['<PAD>'] = 0\n",
        "    answer_tokenizer.word_index['<PAD>'] = 0\n",
        "\n",
        "    # Fit tokenizers\n",
        "    question_tokenizer.fit_on_texts(df[\"question\"])\n",
        "    answer_tokenizer.fit_on_texts(df[\"answer\"])\n",
        "\n",
        "    # Convert to sequences\n",
        "    question_sequences = question_tokenizer.texts_to_sequences(df[\"question\"])\n",
        "    answer_sequences = answer_tokenizer.texts_to_sequences(df[\"answer\"])\n",
        "\n",
        "    # Pad sequences\n",
        "    question_padded = pad_sequences(question_sequences, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
        "    answer_padded = pad_sequences(answer_sequences, maxlen=MAX_ANSWER_LENGTH, padding='post')\n",
        "\n",
        "    return question_padded, answer_padded, question_tokenizer, answer_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34dea60f-dee1-4405-9aed-7fd51385ec2a",
      "metadata": {
        "id": "34dea60f-dee1-4405-9aed-7fd51385ec2a"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e731594-6ab9-4342-8c06-a65dace1f25d",
      "metadata": {
        "id": "6e731594-6ab9-4342-8c06-a65dace1f25d"
      },
      "outputs": [],
      "source": [
        "def build_improved_model(vocab_size_q, vocab_size_a):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,), name='encoder_input')\n",
        "\n",
        "    # Improved embedding with proper initialization\n",
        "    encoder_embedding = Embedding(\n",
        "        vocab_size_q,\n",
        "        EMBEDDING_DIM,\n",
        "        mask_zero=True,\n",
        "        embeddings_initializer='glorot_uniform',\n",
        "        name='encoder_embedding'\n",
        "    )\n",
        "    encoder_embed = encoder_embedding(encoder_inputs)\n",
        "\n",
        "    # Increase dropout rate\n",
        "    encoder_dropout1 = Dropout(0.5)(encoder_embed)\n",
        "\n",
        "    # Add L2 regularization to LSTM layers\n",
        "    encoder_lstm = LSTM(\n",
        "        LATENT_DIM,\n",
        "        return_state=True,\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        recurrent_initializer='orthogonal',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "        recurrent_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "        name='encoder_lstm'\n",
        "    )\n",
        "\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_dropout1)\n",
        "\n",
        "    # Add layer normalization\n",
        "    state_h = LayerNormalization()(state_h)\n",
        "    state_c = LayerNormalization()(state_c)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(MAX_ANSWER_LENGTH-1,), name='decoder_input')\n",
        "\n",
        "    decoder_embedding = Embedding(\n",
        "        vocab_size_a,\n",
        "        EMBEDDING_DIM,\n",
        "        mask_zero=True,\n",
        "        embeddings_initializer='glorot_uniform',\n",
        "        name='decoder_embedding'\n",
        "    )\n",
        "    decoder_embed = decoder_embedding(decoder_inputs)\n",
        "\n",
        "    # Add dropout\n",
        "    decoder_dropout1 = Dropout(0.5)(decoder_embed)\n",
        "\n",
        "    decoder_lstm = LSTM(\n",
        "        LATENT_DIM,\n",
        "        return_sequences=True,\n",
        "        return_state=True,\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        recurrent_initializer='orthogonal',\n",
        "        name='decoder_lstm'\n",
        "    )\n",
        "\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_dropout1, initial_state=[state_h, state_c])\n",
        "\n",
        "    # Add layer normalization\n",
        "    decoder_outputs = LayerNormalization()(decoder_outputs)\n",
        "\n",
        "    # Final dropout before dense layer\n",
        "    decoder_dropout2 = Dropout(0.5)(decoder_outputs)\n",
        "\n",
        "    # Dense layer with proper initialization\n",
        "    decoder_dense = Dense(\n",
        "        vocab_size_a,\n",
        "        activation='softmax',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        name='decoder_dense'\n",
        "    )\n",
        "    decoder_outputs = decoder_dense(decoder_dropout2)\n",
        "\n",
        "    # Define model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    # Custom Adam optimizer with gradient clipping\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        clipnorm=CLIP_NORM,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-7\n",
        "    )\n",
        "\n",
        "    def sparse_categorical_crossentropy_with_smoothing(y_true, y_pred, smoothing=0.1):\n",
        "        num_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true_one_hot = tf.one_hot(y_true, tf.shape(y_pred)[-1])\n",
        "\n",
        "        # Apply label smoothing\n",
        "        y_true_smooth = (1.0 - smoothing) * y_true_one_hot + smoothing / num_classes\n",
        "\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_sum(-y_true_smooth * tf.math.log(y_pred + 1e-7), axis=-1)\n",
        "        )\n",
        "\n",
        "    # Then in the model.compile():\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=sparse_categorical_crossentropy_with_smoothing,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2baa087-00e5-4ee7-b7ad-6ea656ecfc8f",
      "metadata": {
        "id": "a2baa087-00e5-4ee7-b7ad-6ea656ecfc8f"
      },
      "outputs": [],
      "source": [
        "def create_inference_models(model, vocab_size_a):\n",
        "    # Get relevant layers\n",
        "    encoder_lstm = None\n",
        "    decoder_lstm = None\n",
        "    decoder_dense = None\n",
        "    encoder_embedding = None\n",
        "    decoder_embedding = None\n",
        "\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LSTM):\n",
        "            if encoder_lstm is None:\n",
        "                encoder_lstm = layer\n",
        "            else:\n",
        "                decoder_lstm = layer\n",
        "        elif isinstance(layer, Dense):\n",
        "            decoder_dense = layer\n",
        "        elif isinstance(layer, Embedding):\n",
        "            if encoder_embedding is None:\n",
        "                encoder_embedding = layer\n",
        "            else:\n",
        "                decoder_embedding = layer\n",
        "\n",
        "    # Create encoder model\n",
        "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,))\n",
        "    x = encoder_embedding(encoder_inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    _, state_h, state_c = encoder_lstm(x)\n",
        "    state_h = LayerNormalization()(state_h)\n",
        "    state_c = LayerNormalization()(state_c)\n",
        "    encoder_model = Model(encoder_inputs, [state_h, state_c])\n",
        "\n",
        "    # Create decoder model\n",
        "    decoder_inputs = Input(shape=(1,))\n",
        "    decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "    decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "\n",
        "    x = decoder_embedding(decoder_inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        x,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "    decoder_outputs = LayerNormalization()(decoder_outputs)\n",
        "    decoder_outputs = Dropout(0.3)(decoder_outputs)\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs, state_h, state_c]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb51e14-19f6-4799-af04-bdce5083bde2",
      "metadata": {
        "id": "ebb51e14-19f6-4799-af04-bdce5083bde2"
      },
      "source": [
        "## Model Evalutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3cacbb6-d67f-4aea-ba05-ab353adb3333",
      "metadata": {
        "id": "d3cacbb6-d67f-4aea-ba05-ab353adb3333"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(encoder_model, decoder_model, q_test, a_test, answer_tokenizer):\n",
        "    smooth = SmoothingFunction().method1\n",
        "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
        "\n",
        "    total_bleu = 0\n",
        "    total_rouge = 0\n",
        "\n",
        "    for i in range(len(q_test)):\n",
        "        states_value = encoder_model.predict(q_test[i:i+1], verbose=0)\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = answer_tokenizer.word_index.get('<start>', 0)\n",
        "\n",
        "        decoded_tokens = []\n",
        "        while len(decoded_tokens) < MAX_ANSWER_LENGTH:\n",
        "            output_tokens, h, c = decoder_model.predict(\n",
        "                [target_seq] + states_value,\n",
        "                verbose=0\n",
        "            )\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_word = answer_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "            if sampled_word == '<end>' or sampled_word == '':\n",
        "                break\n",
        "\n",
        "            decoded_tokens.append(sampled_word)\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            states_value = [h, c]\n",
        "\n",
        "        reference_tokens = [answer_tokenizer.index_word.get(idx, '')\n",
        "                          for idx in a_test[i] if idx != 0]\n",
        "        reference_tokens = [token for token in reference_tokens\n",
        "                          if token not in ['<start>', '<end>', '<pad>']]\n",
        "\n",
        "        bleu = sentence_bleu([reference_tokens], decoded_tokens, smoothing_function=smooth)\n",
        "        total_bleu += bleu\n",
        "\n",
        "        rouge_scores = rouge_scorer_instance.score(\n",
        "            ' '.join(reference_tokens),\n",
        "            ' '.join(decoded_tokens)\n",
        "        )\n",
        "        total_rouge += rouge_scores['rougeL'].fmeasure\n",
        "\n",
        "    return total_bleu/len(q_test), total_rouge/len(q_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbdd9a2-81e2-4e39-9f89-1eaf43f20262",
      "metadata": {
        "id": "8bbdd9a2-81e2-4e39-9f89-1eaf43f20262"
      },
      "outputs": [],
      "source": [
        "def ask_question(question, encoder_model, decoder_model, q_tokenizer, a_tokenizer, max_length=50):\n",
        "    question = improved_clean_text(question)\n",
        "\n",
        "    q_seq = q_tokenizer.texts_to_sequences([question])\n",
        "    q_seq = pad_sequences(q_seq, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
        "\n",
        "    states_value = encoder_model.predict(q_seq, verbose=0)\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = a_tokenizer.word_index.get('<start>', 0)\n",
        "\n",
        "    decoded_tokens = []\n",
        "\n",
        "    while len(decoded_tokens) < max_length:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = a_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        if sampled_word == '<end>' or sampled_word == '':\n",
        "            break\n",
        "\n",
        "        decoded_tokens.append(sampled_word)\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(decoded_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc27bbe5-3efc-479d-9b70-8571d2ec1bf1",
      "metadata": {
        "id": "dc27bbe5-3efc-479d-9b70-8571d2ec1bf1"
      },
      "source": [
        "## Training and performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf62dfb-f600-47a2-afe6-e338c056168c",
      "metadata": {
        "id": "caf62dfb-f600-47a2-afe6-e338c056168c"
      },
      "outputs": [],
      "source": [
        "class WarmUpLearningRateScheduler(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, warmup_steps, initial_lr):\n",
        "        super().__init__()\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.initial_lr = initial_lr\n",
        "        self.step = 0\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        self.step += 1\n",
        "        if self.step <= self.warmup_steps:\n",
        "            lr = (self.step / self.warmup_steps) * self.initial_lr\n",
        "            self.model.optimizer.learning_rate.assign(lr)\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-4\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=12,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        'best_model.keras',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "callbacks.append(WarmUpLearningRateScheduler(warmup_steps=100, initial_lr=5e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a4d535-5fe1-4d71-99e5-e8909766dd3f",
      "metadata": {
        "id": "c2a4d535-5fe1-4d71-99e5-e8909766dd3f",
        "outputId": "eb8e54da-1abd-473e-a894-9df2d6f8f90e",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ encoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">346,624</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ not_equal_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,620,992</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]        │                 │ not_equal_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ layer_normalization_24        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ layer_normalization_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]        │                 │ layer_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                               │                           │                 │ layer_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ layer_normalization_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6332</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,248,316</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ encoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m346,624\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ encoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ not_equal_16 (\u001b[38;5;33mNotEqual\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,620,992\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │       \u001b[38;5;34m1,574,912\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                               │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]        │                 │ not_equal_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ decoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ layer_normalization_24        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ layer_normalization_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │       \u001b[38;5;34m1,574,912\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                               │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]        │                 │ layer_normalization_24[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                               │                           │                 │ layer_normalization_25[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ layer_normalization_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m6332\u001b[0m)          │       \u001b[38;5;34m3,248,316\u001b[0m │ dropout_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,368,828</span> (31.92 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,368,828\u001b[0m (31.92 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,368,828</span> (31.92 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,368,828\u001b[0m (31.92 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.2187 - loss: 7.2295      \n",
            "Epoch 1: val_loss improved from inf to 5.25599, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 788ms/step - accuracy: 0.2192 - loss: 7.2234 - val_accuracy: 0.3521 - val_loss: 5.2560 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - accuracy: 0.3494 - loss: 5.1978  \n",
            "Epoch 2: val_loss improved from 5.25599 to 4.56926, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 770ms/step - accuracy: 0.3495 - loss: 5.1968 - val_accuracy: 0.4037 - val_loss: 4.5693 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.3993 - loss: 4.5216  \n",
            "Epoch 3: val_loss improved from 4.56926 to 4.01193, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 708ms/step - accuracy: 0.3994 - loss: 4.5210 - val_accuracy: 0.4527 - val_loss: 4.0119 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - accuracy: 0.4412 - loss: 4.0072  \n",
            "Epoch 4: val_loss improved from 4.01193 to 3.52942, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 670ms/step - accuracy: 0.4412 - loss: 4.0065 - val_accuracy: 0.5077 - val_loss: 3.5294 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.5054 - loss: 3.5012  \n",
            "Epoch 5: val_loss improved from 3.52942 to 3.08589, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 648ms/step - accuracy: 0.5054 - loss: 3.5008 - val_accuracy: 0.5798 - val_loss: 3.0859 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step - accuracy: 0.5721 - loss: 3.1047  \n",
            "Epoch 6: val_loss improved from 3.08589 to 2.73003, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 664ms/step - accuracy: 0.5721 - loss: 3.1045 - val_accuracy: 0.6539 - val_loss: 2.7300 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.6245 - loss: 2.8424  \n",
            "Epoch 7: val_loss improved from 2.73003 to 2.45103, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.6246 - loss: 2.8421 - val_accuracy: 0.7197 - val_loss: 2.4510 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step - accuracy: 0.6761 - loss: 2.6095  \n",
            "Epoch 8: val_loss improved from 2.45103 to 2.23562, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 647ms/step - accuracy: 0.6762 - loss: 2.6093 - val_accuracy: 0.7759 - val_loss: 2.2356 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.7150 - loss: 2.4371  \n",
            "Epoch 9: val_loss improved from 2.23562 to 2.07153, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 648ms/step - accuracy: 0.7151 - loss: 2.4370 - val_accuracy: 0.8198 - val_loss: 2.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.7487 - loss: 2.3050  \n",
            "Epoch 10: val_loss improved from 2.07153 to 1.95191, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 660ms/step - accuracy: 0.7487 - loss: 2.3050 - val_accuracy: 0.8539 - val_loss: 1.9519 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638ms/step - accuracy: 0.7706 - loss: 2.2145  \n",
            "Epoch 11: val_loss improved from 1.95191 to 1.86102, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 658ms/step - accuracy: 0.7706 - loss: 2.2144 - val_accuracy: 0.8792 - val_loss: 1.8610 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.7916 - loss: 2.1312  \n",
            "Epoch 12: val_loss improved from 1.86102 to 1.78637, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.7916 - loss: 2.1312 - val_accuracy: 0.9009 - val_loss: 1.7864 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step - accuracy: 0.8069 - loss: 2.0803  \n",
            "Epoch 13: val_loss improved from 1.78637 to 1.73416, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 655ms/step - accuracy: 0.8069 - loss: 2.0802 - val_accuracy: 0.9174 - val_loss: 1.7342 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - accuracy: 0.8228 - loss: 2.0253  \n",
            "Epoch 14: val_loss improved from 1.73416 to 1.68225, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 655ms/step - accuracy: 0.8228 - loss: 2.0252 - val_accuracy: 0.9306 - val_loss: 1.6822 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.8349 - loss: 1.9786  \n",
            "Epoch 15: val_loss improved from 1.68225 to 1.65392, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.8349 - loss: 1.9786 - val_accuracy: 0.9416 - val_loss: 1.6539 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.8462 - loss: 1.9382  \n",
            "Epoch 16: val_loss improved from 1.65392 to 1.61926, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 648ms/step - accuracy: 0.8462 - loss: 1.9382 - val_accuracy: 0.9499 - val_loss: 1.6193 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step - accuracy: 0.8586 - loss: 1.9007  \n",
            "Epoch 17: val_loss improved from 1.61926 to 1.59368, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 650ms/step - accuracy: 0.8586 - loss: 1.9007 - val_accuracy: 0.9590 - val_loss: 1.5937 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637ms/step - accuracy: 0.8673 - loss: 1.8653  \n",
            "Epoch 18: val_loss improved from 1.59368 to 1.56948, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 657ms/step - accuracy: 0.8673 - loss: 1.8654 - val_accuracy: 0.9665 - val_loss: 1.5695 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step - accuracy: 0.8702 - loss: 1.8595  \n",
            "Epoch 19: val_loss improved from 1.56948 to 1.55768, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 876ms/step - accuracy: 0.8703 - loss: 1.8594 - val_accuracy: 0.9685 - val_loss: 1.5577 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.8774 - loss: 1.8283  \n",
            "Epoch 20: val_loss improved from 1.55768 to 1.53821, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 673ms/step - accuracy: 0.8774 - loss: 1.8283 - val_accuracy: 0.9747 - val_loss: 1.5382 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679ms/step - accuracy: 0.8854 - loss: 1.8064  \n",
            "Epoch 21: val_loss improved from 1.53821 to 1.52299, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 700ms/step - accuracy: 0.8854 - loss: 1.8064 - val_accuracy: 0.9781 - val_loss: 1.5230 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.8921 - loss: 1.7810  \n",
            "Epoch 22: val_loss improved from 1.52299 to 1.51604, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 682ms/step - accuracy: 0.8921 - loss: 1.7811 - val_accuracy: 0.9799 - val_loss: 1.5160 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - accuracy: 0.8973 - loss: 1.7625  \n",
            "Epoch 23: val_loss improved from 1.51604 to 1.50748, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 677ms/step - accuracy: 0.8973 - loss: 1.7625 - val_accuracy: 0.9814 - val_loss: 1.5075 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.9028 - loss: 1.7482  \n",
            "Epoch 24: val_loss improved from 1.50748 to 1.49614, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 684ms/step - accuracy: 0.9028 - loss: 1.7482 - val_accuracy: 0.9830 - val_loss: 1.4961 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.9062 - loss: 1.7353  \n",
            "Epoch 25: val_loss improved from 1.49614 to 1.48565, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 694ms/step - accuracy: 0.9062 - loss: 1.7353 - val_accuracy: 0.9866 - val_loss: 1.4856 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - accuracy: 0.9116 - loss: 1.7189  \n",
            "Epoch 26: val_loss improved from 1.48565 to 1.48167, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 669ms/step - accuracy: 0.9116 - loss: 1.7190 - val_accuracy: 0.9862 - val_loss: 1.4817 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.9143 - loss: 1.7033  \n",
            "Epoch 27: val_loss improved from 1.48167 to 1.47332, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 672ms/step - accuracy: 0.9143 - loss: 1.7033 - val_accuracy: 0.9884 - val_loss: 1.4733 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.9185 - loss: 1.6911  \n",
            "Epoch 28: val_loss improved from 1.47332 to 1.46403, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 737ms/step - accuracy: 0.9185 - loss: 1.6911 - val_accuracy: 0.9907 - val_loss: 1.4640 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.9225 - loss: 1.6794  \n",
            "Epoch 29: val_loss improved from 1.46403 to 1.45908, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 733ms/step - accuracy: 0.9225 - loss: 1.6794 - val_accuracy: 0.9907 - val_loss: 1.4591 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - accuracy: 0.9249 - loss: 1.6689  \n",
            "Epoch 30: val_loss improved from 1.45908 to 1.45507, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 722ms/step - accuracy: 0.9249 - loss: 1.6689 - val_accuracy: 0.9916 - val_loss: 1.4551 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.9281 - loss: 1.6573  \n",
            "Epoch 31: val_loss improved from 1.45507 to 1.44926, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 714ms/step - accuracy: 0.9281 - loss: 1.6573 - val_accuracy: 0.9931 - val_loss: 1.4493 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - accuracy: 0.9309 - loss: 1.6471  \n",
            "Epoch 32: val_loss improved from 1.44926 to 1.44222, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 736ms/step - accuracy: 0.9309 - loss: 1.6471 - val_accuracy: 0.9933 - val_loss: 1.4422 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687ms/step - accuracy: 0.9342 - loss: 1.6354  \n",
            "Epoch 33: val_loss improved from 1.44222 to 1.44108, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 708ms/step - accuracy: 0.9342 - loss: 1.6354 - val_accuracy: 0.9936 - val_loss: 1.4411 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - accuracy: 0.9378 - loss: 1.6255  \n",
            "Epoch 34: val_loss improved from 1.44108 to 1.43614, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 769ms/step - accuracy: 0.9378 - loss: 1.6255 - val_accuracy: 0.9945 - val_loss: 1.4361 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.9393 - loss: 1.6190  \n",
            "Epoch 35: val_loss improved from 1.43614 to 1.43241, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 684ms/step - accuracy: 0.9393 - loss: 1.6190 - val_accuracy: 0.9951 - val_loss: 1.4324 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.9413 - loss: 1.6121  \n",
            "Epoch 36: val_loss improved from 1.43241 to 1.42804, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 729ms/step - accuracy: 0.9412 - loss: 1.6121 - val_accuracy: 0.9959 - val_loss: 1.4280 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.9447 - loss: 1.6012  \n",
            "Epoch 37: val_loss improved from 1.42804 to 1.42408, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 802ms/step - accuracy: 0.9447 - loss: 1.6012 - val_accuracy: 0.9961 - val_loss: 1.4241 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - accuracy: 0.9470 - loss: 1.5943  \n",
            "Epoch 38: val_loss improved from 1.42408 to 1.42228, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 728ms/step - accuracy: 0.9470 - loss: 1.5943 - val_accuracy: 0.9965 - val_loss: 1.4223 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658ms/step - accuracy: 0.9471 - loss: 1.5910  \n",
            "Epoch 39: val_loss improved from 1.42228 to 1.41961, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 679ms/step - accuracy: 0.9471 - loss: 1.5910 - val_accuracy: 0.9970 - val_loss: 1.4196 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - accuracy: 0.9486 - loss: 1.5835  \n",
            "Epoch 40: val_loss improved from 1.41961 to 1.41583, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 691ms/step - accuracy: 0.9486 - loss: 1.5835 - val_accuracy: 0.9969 - val_loss: 1.4158 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - accuracy: 0.9521 - loss: 1.5715  \n",
            "Epoch 41: val_loss improved from 1.41583 to 1.41329, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 838ms/step - accuracy: 0.9521 - loss: 1.5716 - val_accuracy: 0.9966 - val_loss: 1.4133 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883ms/step - accuracy: 0.9521 - loss: 1.5702  \n",
            "Epoch 42: val_loss improved from 1.41329 to 1.41126, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 905ms/step - accuracy: 0.9520 - loss: 1.5702 - val_accuracy: 0.9973 - val_loss: 1.4113 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.9536 - loss: 1.5652  \n",
            "Epoch 43: val_loss improved from 1.41126 to 1.40919, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 688ms/step - accuracy: 0.9536 - loss: 1.5652 - val_accuracy: 0.9976 - val_loss: 1.4092 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step - accuracy: 0.9555 - loss: 1.5604  \n",
            "Epoch 44: val_loss improved from 1.40919 to 1.40832, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 691ms/step - accuracy: 0.9555 - loss: 1.5604 - val_accuracy: 0.9977 - val_loss: 1.4083 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.9571 - loss: 1.5530  \n",
            "Epoch 45: val_loss improved from 1.40832 to 1.40532, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 738ms/step - accuracy: 0.9571 - loss: 1.5530 - val_accuracy: 0.9976 - val_loss: 1.4053 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.9589 - loss: 1.5499  \n",
            "Epoch 46: val_loss improved from 1.40532 to 1.40069, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 730ms/step - accuracy: 0.9589 - loss: 1.5499 - val_accuracy: 0.9978 - val_loss: 1.4007 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - accuracy: 0.9594 - loss: 1.5458  \n",
            "Epoch 47: val_loss did not improve from 1.40069\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 722ms/step - accuracy: 0.9594 - loss: 1.5458 - val_accuracy: 0.9982 - val_loss: 1.4013 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.9614 - loss: 1.5393  \n",
            "Epoch 48: val_loss improved from 1.40069 to 1.39924, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 699ms/step - accuracy: 0.9614 - loss: 1.5393 - val_accuracy: 0.9982 - val_loss: 1.3992 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.9630 - loss: 1.5347  \n",
            "Epoch 49: val_loss improved from 1.39924 to 1.39742, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 755ms/step - accuracy: 0.9630 - loss: 1.5347 - val_accuracy: 0.9988 - val_loss: 1.3974 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step - accuracy: 0.9641 - loss: 1.5289  \n",
            "Epoch 50: val_loss did not improve from 1.39742\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 823ms/step - accuracy: 0.9641 - loss: 1.5289 - val_accuracy: 0.9985 - val_loss: 1.3979 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.9647 - loss: 1.5249  \n",
            "Epoch 51: val_loss improved from 1.39742 to 1.39463, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 721ms/step - accuracy: 0.9647 - loss: 1.5249 - val_accuracy: 0.9984 - val_loss: 1.3946 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.9654 - loss: 1.5231  \n",
            "Epoch 52: val_loss improved from 1.39463 to 1.39314, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 690ms/step - accuracy: 0.9654 - loss: 1.5231 - val_accuracy: 0.9985 - val_loss: 1.3931 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664ms/step - accuracy: 0.9671 - loss: 1.5160  \n",
            "Epoch 53: val_loss improved from 1.39314 to 1.39295, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 685ms/step - accuracy: 0.9671 - loss: 1.5160 - val_accuracy: 0.9984 - val_loss: 1.3930 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674ms/step - accuracy: 0.9680 - loss: 1.5140  \n",
            "Epoch 54: val_loss improved from 1.39295 to 1.39105, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 696ms/step - accuracy: 0.9680 - loss: 1.5140 - val_accuracy: 0.9989 - val_loss: 1.3911 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - accuracy: 0.9693 - loss: 1.5080  \n",
            "Epoch 55: val_loss improved from 1.39105 to 1.39058, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 684ms/step - accuracy: 0.9693 - loss: 1.5080 - val_accuracy: 0.9982 - val_loss: 1.3906 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - accuracy: 0.9703 - loss: 1.5042  \n",
            "Epoch 56: val_loss improved from 1.39058 to 1.38827, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 687ms/step - accuracy: 0.9703 - loss: 1.5042 - val_accuracy: 0.9988 - val_loss: 1.3883 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.9713 - loss: 1.5035  \n",
            "Epoch 57: val_loss improved from 1.38827 to 1.38678, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 665ms/step - accuracy: 0.9713 - loss: 1.5035 - val_accuracy: 0.9991 - val_loss: 1.3868 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - accuracy: 0.9718 - loss: 1.4992  \n",
            "Epoch 58: val_loss improved from 1.38678 to 1.38622, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 673ms/step - accuracy: 0.9718 - loss: 1.4992 - val_accuracy: 0.9987 - val_loss: 1.3862 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.9732 - loss: 1.4973  \n",
            "Epoch 59: val_loss improved from 1.38622 to 1.38476, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 756ms/step - accuracy: 0.9732 - loss: 1.4973 - val_accuracy: 0.9988 - val_loss: 1.3848 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9729 - loss: 1.4948  \n",
            "Epoch 60: val_loss improved from 1.38476 to 1.38337, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 785ms/step - accuracy: 0.9729 - loss: 1.4948 - val_accuracy: 0.9992 - val_loss: 1.3834 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9745 - loss: 1.4895  \n",
            "Epoch 61: val_loss improved from 1.38337 to 1.38059, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 782ms/step - accuracy: 0.9745 - loss: 1.4895 - val_accuracy: 0.9992 - val_loss: 1.3806 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9758 - loss: 1.4843  \n",
            "Epoch 62: val_loss improved from 1.38059 to 1.37991, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 783ms/step - accuracy: 0.9758 - loss: 1.4844 - val_accuracy: 0.9993 - val_loss: 1.3799 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.9760 - loss: 1.4861  \n",
            "Epoch 63: val_loss improved from 1.37991 to 1.37899, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 741ms/step - accuracy: 0.9760 - loss: 1.4861 - val_accuracy: 0.9991 - val_loss: 1.3790 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.9771 - loss: 1.4793  \n",
            "Epoch 64: val_loss improved from 1.37899 to 1.37846, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 790ms/step - accuracy: 0.9771 - loss: 1.4793 - val_accuracy: 0.9992 - val_loss: 1.3785 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773ms/step - accuracy: 0.9766 - loss: 1.4795  \n",
            "Epoch 65: val_loss improved from 1.37846 to 1.37707, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 796ms/step - accuracy: 0.9766 - loss: 1.4795 - val_accuracy: 0.9991 - val_loss: 1.3771 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - accuracy: 0.9778 - loss: 1.4746  \n",
            "Epoch 66: val_loss improved from 1.37707 to 1.37640, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 801ms/step - accuracy: 0.9778 - loss: 1.4746 - val_accuracy: 0.9992 - val_loss: 1.3764 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9785 - loss: 1.4718  \n",
            "Epoch 67: val_loss improved from 1.37640 to 1.37353, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 780ms/step - accuracy: 0.9785 - loss: 1.4718 - val_accuracy: 0.9992 - val_loss: 1.3735 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9796 - loss: 1.4703  \n",
            "Epoch 68: val_loss did not improve from 1.37353\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 778ms/step - accuracy: 0.9795 - loss: 1.4703 - val_accuracy: 0.9991 - val_loss: 1.3745 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9794 - loss: 1.4679  \n",
            "Epoch 69: val_loss did not improve from 1.37353\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 778ms/step - accuracy: 0.9794 - loss: 1.4679 - val_accuracy: 0.9991 - val_loss: 1.3745 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.9803 - loss: 1.4658  \n",
            "Epoch 70: val_loss improved from 1.37353 to 1.37147, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 781ms/step - accuracy: 0.9803 - loss: 1.4658 - val_accuracy: 0.9993 - val_loss: 1.3715 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.9801 - loss: 1.4655  \n",
            "Epoch 71: val_loss did not improve from 1.37147\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 789ms/step - accuracy: 0.9801 - loss: 1.4655 - val_accuracy: 0.9992 - val_loss: 1.3723 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.9799 - loss: 1.4677  \n",
            "Epoch 72: val_loss improved from 1.37147 to 1.36974, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 790ms/step - accuracy: 0.9799 - loss: 1.4676 - val_accuracy: 0.9994 - val_loss: 1.3697 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.9817 - loss: 1.4598  \n",
            "Epoch 73: val_loss improved from 1.36974 to 1.36881, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 774ms/step - accuracy: 0.9817 - loss: 1.4598 - val_accuracy: 0.9993 - val_loss: 1.3688 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.9826 - loss: 1.4572  \n",
            "Epoch 74: val_loss improved from 1.36881 to 1.36746, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 778ms/step - accuracy: 0.9826 - loss: 1.4572 - val_accuracy: 0.9992 - val_loss: 1.3675 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749ms/step - accuracy: 0.9817 - loss: 1.4580  \n",
            "Epoch 75: val_loss did not improve from 1.36746\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 770ms/step - accuracy: 0.9817 - loss: 1.4580 - val_accuracy: 0.9993 - val_loss: 1.3686 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.9829 - loss: 1.4565  \n",
            "Epoch 76: val_loss did not improve from 1.36746\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 773ms/step - accuracy: 0.9829 - loss: 1.4565 - val_accuracy: 0.9993 - val_loss: 1.3677 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.9834 - loss: 1.4534  \n",
            "Epoch 77: val_loss improved from 1.36746 to 1.36657, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 784ms/step - accuracy: 0.9834 - loss: 1.4534 - val_accuracy: 0.9993 - val_loss: 1.3666 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.9835 - loss: 1.4503  \n",
            "Epoch 78: val_loss improved from 1.36657 to 1.36484, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 776ms/step - accuracy: 0.9835 - loss: 1.4503 - val_accuracy: 0.9992 - val_loss: 1.3648 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - accuracy: 0.9848 - loss: 1.4466  \n",
            "Epoch 79: val_loss improved from 1.36484 to 1.36336, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 784ms/step - accuracy: 0.9848 - loss: 1.4466 - val_accuracy: 0.9991 - val_loss: 1.3634 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9846 - loss: 1.4487  \n",
            "Epoch 80: val_loss did not improve from 1.36336\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 776ms/step - accuracy: 0.9846 - loss: 1.4487 - val_accuracy: 0.9992 - val_loss: 1.3642 - learning_rate: 5.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775ms/step - accuracy: 0.9851 - loss: 1.4465  \n",
            "Epoch 81: val_loss improved from 1.36336 to 1.36223, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 802ms/step - accuracy: 0.9851 - loss: 1.4465 - val_accuracy: 0.9990 - val_loss: 1.3622 - learning_rate: 5.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9847 - loss: 1.4427     \n",
            "Epoch 82: val_loss improved from 1.36223 to 1.36206, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.9847 - loss: 1.4427 - val_accuracy: 0.9992 - val_loss: 1.3621 - learning_rate: 5.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9853 - loss: 1.4429  \n",
            "Epoch 83: val_loss improved from 1.36206 to 1.35981, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2s/step - accuracy: 0.9853 - loss: 1.4429 - val_accuracy: 0.9996 - val_loss: 1.3598 - learning_rate: 5.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9858 - loss: 1.4390  \n",
            "Epoch 84: val_loss did not improve from 1.35981\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 2s/step - accuracy: 0.9858 - loss: 1.4391 - val_accuracy: 0.9993 - val_loss: 1.3607 - learning_rate: 5.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9866 - loss: 1.4360  \n",
            "Epoch 85: val_loss did not improve from 1.35981\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9866 - loss: 1.4360 - val_accuracy: 0.9994 - val_loss: 1.3600 - learning_rate: 5.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 1.4376  \n",
            "Epoch 86: val_loss improved from 1.35981 to 1.35965, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.9862 - loss: 1.4376 - val_accuracy: 0.9995 - val_loss: 1.3597 - learning_rate: 5.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894ms/step - accuracy: 0.9874 - loss: 1.4350  \n",
            "Epoch 87: val_loss improved from 1.35965 to 1.35651, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 964ms/step - accuracy: 0.9874 - loss: 1.4350 - val_accuracy: 0.9991 - val_loss: 1.3565 - learning_rate: 5.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9869 - loss: 1.4344  \n",
            "Epoch 88: val_loss improved from 1.35651 to 1.35620, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 1s/step - accuracy: 0.9869 - loss: 1.4344 - val_accuracy: 0.9993 - val_loss: 1.3562 - learning_rate: 5.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 1.4327  \n",
            "Epoch 89: val_loss did not improve from 1.35620\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 1.4327 - val_accuracy: 0.9993 - val_loss: 1.3582 - learning_rate: 5.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9882 - loss: 1.4289  \n",
            "Epoch 90: val_loss improved from 1.35620 to 1.35532, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.9882 - loss: 1.4289 - val_accuracy: 0.9995 - val_loss: 1.3553 - learning_rate: 5.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9886 - loss: 1.4294  \n",
            "Epoch 91: val_loss did not improve from 1.35532\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 1s/step - accuracy: 0.9886 - loss: 1.4294 - val_accuracy: 0.9994 - val_loss: 1.3557 - learning_rate: 5.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 1.4294  \n",
            "Epoch 92: val_loss improved from 1.35532 to 1.35403, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 1.4294 - val_accuracy: 0.9996 - val_loss: 1.3540 - learning_rate: 5.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9886 - loss: 1.4245  \n",
            "Epoch 93: val_loss did not improve from 1.35403\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - accuracy: 0.9886 - loss: 1.4245 - val_accuracy: 0.9993 - val_loss: 1.3549 - learning_rate: 5.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9885 - loss: 1.4274  \n",
            "Epoch 94: val_loss improved from 1.35403 to 1.35289, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9885 - loss: 1.4274 - val_accuracy: 0.9995 - val_loss: 1.3529 - learning_rate: 5.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4227  \n",
            "Epoch 95: val_loss did not improve from 1.35289\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4227 - val_accuracy: 0.9995 - val_loss: 1.3529 - learning_rate: 5.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4226  \n",
            "Epoch 96: val_loss improved from 1.35289 to 1.35004, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 1.4226 - val_accuracy: 0.9996 - val_loss: 1.3500 - learning_rate: 5.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9893 - loss: 1.4240  \n",
            "Epoch 97: val_loss improved from 1.35004 to 1.35003, saving model to best_model.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.9893 - loss: 1.4240 - val_accuracy: 0.9995 - val_loss: 1.3500 - learning_rate: 5.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 1.4201  \n",
            "Epoch 98: val_loss did not improve from 1.35003\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 2s/step - accuracy: 0.9897 - loss: 1.4202 - val_accuracy: 0.9997 - val_loss: 1.3522 - learning_rate: 5.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4178  \n",
            "Epoch 99: val_loss did not improve from 1.35003\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4178 - val_accuracy: 0.9994 - val_loss: 1.3514 - learning_rate: 5.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4181  \n",
            "Epoch 100: val_loss did not improve from 1.35003\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 1.4181 - val_accuracy: 0.9994 - val_loss: 1.3503 - learning_rate: 5.0000e-04\n",
            "\n",
            "Evaluation Results:\n",
            "BLEU Score: 0.9533\n",
            "ROUGE Score: 0.9635\n"
          ]
        }
      ],
      "source": [
        "df = load_data(\"dataset\")\n",
        "q_data, a_data, q_tokenizer, a_tokenizer = preprocess_data(df)\n",
        "\n",
        "# Split data\n",
        "indices = np.arange(len(q_data))\n",
        "np.random.shuffle(indices)\n",
        "q_data = q_data[indices]\n",
        "a_data = a_data[indices]\n",
        "\n",
        "num_val = int(len(q_data) * VALIDATION_SPLIT)\n",
        "num_test = int(len(q_data) * TEST_SPLIT)\n",
        "\n",
        "q_train = q_data[:-num_val-num_test]\n",
        "a_train = a_data[:-num_val-num_test]\n",
        "q_val = q_data[-num_val-num_test:-num_test]\n",
        "a_val = a_data[-num_val-num_test:-num_test]\n",
        "q_test = q_data[-num_test:]\n",
        "a_test = a_data[-num_test:]\n",
        "\n",
        "# Build and train model\n",
        "model = build_improved_model(len(q_tokenizer.word_index) + 1, len(a_tokenizer.word_index) + 1)\n",
        "\n",
        "history = model.fit(\n",
        "    [q_train, a_train[:, :-1]],\n",
        "    a_train[:, 1:],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=([q_val, a_val[:, :-1]], a_val[:, 1:]),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Create inference models\n",
        "encoder_model, decoder_model = create_inference_models(model, len(a_tokenizer.word_index) + 1)\n",
        "\n",
        "# Evaluate\n",
        "bleu_score, rouge_score = evaluate_model(encoder_model, decoder_model, q_test, a_test, a_tokenizer)\n",
        "\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "print(f\"ROUGE Score: {rouge_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "190debc0-d689-432d-9bbf-44a497eaaedd",
      "metadata": {
        "id": "190debc0-d689-432d-9bbf-44a497eaaedd",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Final Tuned LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b792c5b-bb43-432c-a168-8c435c85623a",
      "metadata": {
        "id": "6b792c5b-bb43-432c-a168-8c435c85623a"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4788e6e5-433d-4d08-b602-71b5fde3b8ba",
      "metadata": {
        "id": "4788e6e5-433d-4d08-b602-71b5fde3b8ba"
      },
      "outputs": [],
      "source": [
        "MAX_QUESTION_LENGTH = 50\n",
        "MAX_ANSWER_LENGTH = 200\n",
        "EMBEDDING_DIM = 256\n",
        "LATENT_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "TEST_SPLIT = 0.2\n",
        "LEARNING_RATE = 1e-4\n",
        "CLIP_NORM = 1.0\n",
        "BEAM_WIDTH = 3\n",
        "TEMPERATURE = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0975c0-ad56-41cd-a7d2-b41c677c4160",
      "metadata": {
        "id": "2e0975c0-ad56-41cd-a7d2-b41c677c4160"
      },
      "outputs": [],
      "source": [
        "def augment_data(question, answer):\n",
        "    augmented_pairs = []\n",
        "    # Original pair\n",
        "    augmented_pairs.append((question, answer))\n",
        "\n",
        "    # Remove punctuation version\n",
        "    q_no_punct = re.sub(r'[.,!?]', '', question)\n",
        "    augmented_pairs.append((q_no_punct, answer))\n",
        "\n",
        "    # Shuffle words slightly (maintaining rough meaning)\n",
        "    words = question.split()\n",
        "    if len(words) > 3:\n",
        "        for i in range(min(3, len(words)-1)):\n",
        "            shuffled = words.copy()\n",
        "            shuffled[i], shuffled[i+1] = shuffled[i+1], shuffled[i]\n",
        "            augmented_pairs.append((' '.join(shuffled), answer))\n",
        "\n",
        "    return augmented_pairs\n",
        "\n",
        "def get_synonyms(word):\n",
        "    try:\n",
        "        synonyms = []\n",
        "        for syn in wordnet.synsets(word):\n",
        "            for lemma in syn.lemmas():\n",
        "                if lemma.name() != word and '_' not in lemma.name():\n",
        "                    synonyms.append(lemma.name())\n",
        "        return list(set(synonyms))\n",
        "    except LookupError:\n",
        "        nltk.download('wordnet')\n",
        "        return get_synonyms(word)\n",
        "    except Exception as e:\n",
        "        print(f\"Synonym error: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def advanced_augment_data(question, answer, augmentation_factor=3):\n",
        "    augmented_pairs = [(question, answer)]\n",
        "\n",
        "    # 1. Synonym replacement\n",
        "    words = question.split()\n",
        "    for _ in range(min(3, len(words))):\n",
        "        new_words = words.copy()\n",
        "        idx = random.randint(0, len(words)-1)\n",
        "        synonyms = get_synonyms(words[idx])\n",
        "        if synonyms:\n",
        "            new_words[idx] = random.choice(synonyms)\n",
        "            augmented_pairs.append((' '.join(new_words), answer))\n",
        "\n",
        "    # 2. Random deletion\n",
        "    if len(words) > 4:\n",
        "        new_words = [word for word in words if random.random() > 0.2]\n",
        "        if new_words:\n",
        "            augmented_pairs.append((' '.join(new_words), answer))\n",
        "\n",
        "    # 3. Word order variations\n",
        "    if len(augmented_pairs) < augmentation_factor:\n",
        "        if len(words) > 3:\n",
        "            for i in range(min(2, len(words)-1)):\n",
        "                shuffled = words.copy()\n",
        "                shuffled[i], shuffled[i+1] = shuffled[i+1], shuffled[i]\n",
        "                augmented_pairs.append((' '.join(shuffled), answer))\n",
        "\n",
        "    # 4. Remove punctuation version\n",
        "    q_no_punct = re.sub(r'[.,!?]', '', question)\n",
        "    if q_no_punct != question:\n",
        "        augmented_pairs.append((q_no_punct, answer))\n",
        "\n",
        "    return augmented_pairs[:augmentation_factor]\n",
        "\n",
        "def load_data(dataset_path):\n",
        "    data = []\n",
        "    for file in sorted(os.listdir(dataset_path)):\n",
        "        if file.endswith(\".json\"):\n",
        "            with open(os.path.join(dataset_path, file), \"r\", encoding=\"utf-8\") as f:\n",
        "                content = json.load(f)\n",
        "                qa_pairs = content.get(\"qa_pairs\", [])\n",
        "                for pair in qa_pairs:\n",
        "                    augmented = augment_data(pair[\"question\"], pair[\"answer\"])\n",
        "                    for q, a in augmented:\n",
        "                        data.append({\"question\": q, \"answer\": a})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def improved_clean_text(text):\n",
        "    text = text.lower().strip()\n",
        "    # Preserve more meaningful punctuation and symbols\n",
        "    text = re.sub(r'[^\\w\\s.,!?\\'\"-:;$%#@&*()]', ' ', text)\n",
        "    # Normalize numbers\n",
        "    text = re.sub(r'\\d+', 'NUM', text)\n",
        "    # Normalize spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return f\"<START> {text} <END>\"\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df[\"question\"] = df[\"question\"].apply(improved_clean_text)\n",
        "    df[\"answer\"] = df[\"answer\"].apply(improved_clean_text)\n",
        "\n",
        "    # Create tokenizers with additional special tokens\n",
        "    question_tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='')\n",
        "    answer_tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='')\n",
        "\n",
        "    # Add padding token\n",
        "    question_tokenizer.word_index['<PAD>'] = 0\n",
        "    answer_tokenizer.word_index['<PAD>'] = 0\n",
        "\n",
        "    # Fit tokenizers\n",
        "    question_tokenizer.fit_on_texts(df[\"question\"])\n",
        "    answer_tokenizer.fit_on_texts(df[\"answer\"])\n",
        "\n",
        "    # Convert to sequences\n",
        "    question_sequences = question_tokenizer.texts_to_sequences(df[\"question\"])\n",
        "    answer_sequences = answer_tokenizer.texts_to_sequences(df[\"answer\"])\n",
        "\n",
        "    # Pad sequences\n",
        "    question_padded = pad_sequences(question_sequences, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
        "    answer_padded = pad_sequences(answer_sequences, maxlen=MAX_ANSWER_LENGTH, padding='post')\n",
        "\n",
        "    return question_padded, answer_padded, question_tokenizer, answer_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0973cf5d-6355-41b9-8c4e-50d8457ec5ed",
      "metadata": {
        "id": "0973cf5d-6355-41b9-8c4e-50d8457ec5ed"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b0ec4b8-0012-4718-8e09-fb2123f7adc6",
      "metadata": {
        "id": "1b0ec4b8-0012-4718-8e09-fb2123f7adc6"
      },
      "outputs": [],
      "source": [
        "class ResidualLSTMCell(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super(ResidualLSTMCell, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, states, training=None):\n",
        "        h_prev, c_prev = states\n",
        "        outputs, [h, c] = self.lstm_cell(inputs, [h_prev, c_prev], training=training)\n",
        "\n",
        "        # Apply residual connection if dimensions match\n",
        "        if inputs.shape[-1] == self.units:\n",
        "            outputs = outputs + inputs\n",
        "\n",
        "        outputs = self.layer_norm(outputs)\n",
        "        outputs = self.dropout(outputs, training=training)\n",
        "        return outputs, [h, c]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ResidualLSTMCell, self).get_config()\n",
        "        config.update({\"units\": self.units})\n",
        "        return config\n",
        "\n",
        "class ResidualLSTM(tf.keras.layers.RNN):\n",
        "    def __init__(self, units, return_sequences=False, return_state=False, **kwargs):\n",
        "        cell = ResidualLSTMCell(units)\n",
        "        super(ResidualLSTM, self).__init__(\n",
        "            cell, return_sequences=return_sequences, return_state=return_state, **kwargs\n",
        "        )\n",
        "        self.units = units\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ResidualLSTM, self).get_config()\n",
        "        config.update({\"units\": self.units})\n",
        "        return config\n",
        "\n",
        "def build_improved_model(vocab_size_q, vocab_size_a, num_encoder_layers=2, num_decoder_layers=2):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,), name='encoder_input')\n",
        "\n",
        "    # Embedding layer\n",
        "    encoder_embedding = Embedding(\n",
        "        vocab_size_q,\n",
        "        EMBEDDING_DIM,\n",
        "        mask_zero=True,\n",
        "        embeddings_initializer='glorot_uniform',\n",
        "        name='encoder_embedding'\n",
        "    )\n",
        "    x = encoder_embedding(encoder_inputs)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Stacked ResLSTM for encoder with residual connections\n",
        "    encoder_states = []\n",
        "    for i in range(num_encoder_layers):\n",
        "        res_input = x\n",
        "        lstm_layer = LSTM(\n",
        "            LATENT_DIM,\n",
        "            return_sequences=(i < num_encoder_layers - 1),\n",
        "            return_state=True,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "            recurrent_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "            name=f'encoder_lstm_{i}'\n",
        "        )\n",
        "\n",
        "        if i < num_encoder_layers - 1:\n",
        "            x, state_h, state_c = lstm_layer(x)\n",
        "            # Residual connection\n",
        "            if i > 0:  # Skip first layer for residual connection\n",
        "                x = Add()([x, res_input])\n",
        "            x = LayerNormalization()(x)\n",
        "            x = Dropout(0.2)(x)\n",
        "        else:\n",
        "            # Last layer\n",
        "            _, state_h, state_c = lstm_layer(x)\n",
        "\n",
        "        state_h = LayerNormalization()(state_h)\n",
        "        state_c = LayerNormalization()(state_c)\n",
        "        encoder_states.append([state_h, state_c])\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(MAX_ANSWER_LENGTH-1,), name='decoder_input')\n",
        "\n",
        "    decoder_embedding = Embedding(\n",
        "        vocab_size_a,\n",
        "        EMBEDDING_DIM,\n",
        "        mask_zero=True,\n",
        "        embeddings_initializer='glorot_uniform',\n",
        "        name='decoder_embedding'\n",
        "    )\n",
        "    x = decoder_embedding(decoder_inputs)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Stacked LSTM for decoder with residual connections\n",
        "    decoder_states = encoder_states[-1]  # Start with final encoder states\n",
        "    for i in range(num_decoder_layers):\n",
        "        res_input = x\n",
        "        lstm_layer = LSTM(\n",
        "            LATENT_DIM,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            name=f'decoder_lstm_{i}'\n",
        "        )\n",
        "\n",
        "        if i == 0:\n",
        "            # First decoder layer uses encoder final states\n",
        "            x, _, _ = lstm_layer(x, initial_state=decoder_states)\n",
        "        else:\n",
        "            x, _, _ = lstm_layer(x)\n",
        "\n",
        "        # Residual connection\n",
        "        if i > 0:  # Skip first layer for residual\n",
        "            x = Add()([x, res_input])\n",
        "\n",
        "        x = LayerNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "    # Final dense layer\n",
        "    decoder_dense = Dense(\n",
        "        vocab_size_a,\n",
        "        activation='softmax',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        name='decoder_dense'\n",
        "    )\n",
        "    decoder_outputs = decoder_dense(x)\n",
        "\n",
        "    # Define model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    # Custom Adam optimizer with gradient clipping\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        clipnorm=CLIP_NORM,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-7\n",
        "    )\n",
        "\n",
        "    def sparse_categorical_crossentropy_with_smoothing(y_true, y_pred, smoothing=0.1):\n",
        "        num_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true_one_hot = tf.one_hot(y_true, tf.shape(y_pred)[-1])\n",
        "\n",
        "        # Apply label smoothing\n",
        "        y_true_smooth = (1.0 - smoothing) * y_true_one_hot + smoothing / num_classes\n",
        "\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_sum(-y_true_smooth * tf.math.log(y_pred + 1e-7), axis=-1)\n",
        "        )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=sparse_categorical_crossentropy_with_smoothing,\n",
        "        metrics=['accuracy', 'sparse_categorical_accuracy',\n",
        "                tf.keras.metrics.SparseCategoricalCrossentropy(name='raw_crossentropy')]\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "93adade3-ddda-4ec0-bd7f-680bf2632f2f",
      "metadata": {
        "id": "93adade3-ddda-4ec0-bd7f-680bf2632f2f"
      },
      "outputs": [],
      "source": [
        "def create_inference_models(model, vocab_size_a):\n",
        "    # Extract encoder layers\n",
        "    encoder_embeddings = model.get_layer('encoder_embedding')\n",
        "    encoder_lstm_layers = [layer for layer in model.layers\n",
        "                          if 'encoder_lstm' in layer.name and isinstance(layer, LSTM)]\n",
        "\n",
        "    # Extract decoder layers\n",
        "    decoder_embeddings = model.get_layer('decoder_embedding')\n",
        "    decoder_lstm_layers = [layer for layer in model.layers\n",
        "                          if 'decoder_lstm' in layer.name and isinstance(layer, LSTM)]\n",
        "    decoder_dense = model.get_layer('decoder_dense')\n",
        "\n",
        "    # Create encoder model\n",
        "    encoder_inputs = Input(shape=(MAX_QUESTION_LENGTH,))\n",
        "    x = encoder_embeddings(encoder_inputs)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    encoder_states = []\n",
        "    for i, lstm_layer in enumerate(encoder_lstm_layers):\n",
        "        res_input = x\n",
        "        if i < len(encoder_lstm_layers) - 1:\n",
        "            x, state_h, state_c = lstm_layer(x)\n",
        "            if i > 0:\n",
        "                x = Add()([x, res_input])\n",
        "            x = LayerNormalization()(x)\n",
        "            x = Dropout(0.2)(x)\n",
        "        else:\n",
        "            # Last layer\n",
        "            _, state_h, state_c = lstm_layer(x)\n",
        "\n",
        "        state_h = LayerNormalization()(state_h)\n",
        "        state_c = LayerNormalization()(state_c)\n",
        "        encoder_states.extend([state_h, state_c])\n",
        "\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Create decoder model\n",
        "    num_decoder_layers = len(decoder_lstm_layers)\n",
        "    decoder_inputs = Input(shape=(1,))\n",
        "\n",
        "    # States from encoder and previous decoder step\n",
        "    decoder_state_inputs = []\n",
        "    for i in range(num_decoder_layers):\n",
        "        decoder_state_inputs.append(Input(shape=(LATENT_DIM,)))  # h state\n",
        "        decoder_state_inputs.append(Input(shape=(LATENT_DIM,)))  # c state\n",
        "\n",
        "    # Initial decoder embedding\n",
        "    x = decoder_embeddings(decoder_inputs)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    decoder_states = []\n",
        "    for i, lstm_layer in enumerate(decoder_lstm_layers):\n",
        "        res_input = x\n",
        "        h_state_idx = i * 2\n",
        "        c_state_idx = i * 2 + 1\n",
        "\n",
        "        x, state_h, state_c = lstm_layer(\n",
        "            x, initial_state=[decoder_state_inputs[h_state_idx],\n",
        "                             decoder_state_inputs[c_state_idx]]\n",
        "        )\n",
        "\n",
        "        if i > 0:  # Apply residual connection\n",
        "            x = Add()([x, res_input])\n",
        "\n",
        "        x = LayerNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        decoder_states.extend([state_h, state_c])\n",
        "\n",
        "    decoder_outputs = decoder_dense(x)\n",
        "\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_state_inputs,\n",
        "        [decoder_outputs] + decoder_states\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdfc2158-b836-4d5a-ab15-cb905746eaa9",
      "metadata": {
        "id": "fdfc2158-b836-4d5a-ab15-cb905746eaa9"
      },
      "outputs": [],
      "source": [
        "@tf.function(reduce_retracing=True)\n",
        "def predict_step(decoder_model, target_seq, h_batch, c_batch):\n",
        "    return decoder_model([target_seq, h_batch, c_batch], training=False)\n",
        "\n",
        "def optimized_beam_search_decode(encoder_model, decoder_model, input_seq, a_tokenizer,\n",
        "                               beam_width=3, max_length=50, temperature=1.0,\n",
        "                               early_stopping_threshold=0.001):\n",
        "    # Get number of states from encoder model output\n",
        "    num_states = len(encoder_model.outputs)\n",
        "\n",
        "    # Convert input types to tensors with fixed shapes\n",
        "    input_seq = tf.convert_to_tensor(input_seq, dtype=tf.float32)\n",
        "\n",
        "    # Get encoder output (only once)\n",
        "    encoder_states = encoder_model(input_seq, training=False)\n",
        "    if not isinstance(encoder_states, list):\n",
        "        encoder_states = [encoder_states]\n",
        "\n",
        "    # Initialize beam with start token\n",
        "    start_token = a_tokenizer.word_index['<start>']\n",
        "    end_token = a_tokenizer.word_index['<end>']\n",
        "\n",
        "    beams = [(([start_token], 0.0), encoder_states)]\n",
        "    finished_beams = []\n",
        "\n",
        "    # Cache for storing decoder outputs\n",
        "    prediction_cache = {}\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        if not beams:\n",
        "            break\n",
        "\n",
        "        # Prepare batched inputs\n",
        "        current_tokens = np.array([beam[0][0][-1] for beam in beams])\n",
        "        current_states_list = [beam[1] for beam in beams]\n",
        "\n",
        "        # Create batched inputs\n",
        "        batch_size = len(beams)\n",
        "        target_seq = tf.convert_to_tensor(\n",
        "            current_tokens.reshape(batch_size, 1),\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        cache_key = tuple(current_tokens)\n",
        "        if cache_key not in prediction_cache:\n",
        "            # Prepare batched states\n",
        "            batched_states = []\n",
        "            for i in range(num_states):\n",
        "                state_batch = tf.convert_to_tensor(\n",
        "                    np.vstack([states[i] for states in current_states_list]),\n",
        "                    dtype=tf.float32\n",
        "                )\n",
        "                batched_states.append(state_batch)\n",
        "\n",
        "            # Batch predict\n",
        "            outputs_batch = decoder_model(\n",
        "                [target_seq] + batched_states,\n",
        "                training=False\n",
        "            )\n",
        "            prediction_cache[cache_key] = outputs_batch\n",
        "        else:\n",
        "            outputs_batch = prediction_cache[cache_key]\n",
        "\n",
        "        # First output is token probabilities, rest are updated states\n",
        "        output_tokens_batch = outputs_batch[0]\n",
        "        updated_states_batch = outputs_batch[1:]\n",
        "\n",
        "        candidates = []\n",
        "        for i, ((seq, score), _) in enumerate(beams):\n",
        "            if seq[-1] == end_token:\n",
        "                finished_beams.append((seq, score))\n",
        "                continue\n",
        "\n",
        "            # Apply temperature scaling\n",
        "            logits = tf.cast(output_tokens_batch[i, -1, :], tf.float32)\n",
        "            scaled_logits = logits / temperature\n",
        "            scaled_probs = tf.nn.softmax(scaled_logits).numpy()\n",
        "\n",
        "            # Get top k candidates efficiently\n",
        "            top_k_indices = np.argpartition(scaled_probs, -beam_width)[-beam_width:]\n",
        "            top_k_probs = scaled_probs[top_k_indices]\n",
        "\n",
        "            # Extract states for this beam\n",
        "            beam_states = []\n",
        "            for j in range(num_states):\n",
        "                beam_states.append(updated_states_batch[j][i:i+1])\n",
        "\n",
        "            for idx, prob in zip(top_k_indices, top_k_probs):\n",
        "                new_seq = seq + [idx]\n",
        "                new_score = score + float(tf.math.log(prob + 1e-10))\n",
        "                candidates.append(((new_seq, new_score), beam_states))\n",
        "\n",
        "        # Early stopping check\n",
        "        if finished_beams:\n",
        "            best_finished_score = max(score for _, score in finished_beams)\n",
        "            candidates = [c for c in candidates\n",
        "                         if c[0][1] + early_stopping_threshold >= best_finished_score]\n",
        "\n",
        "        # Select top beams\n",
        "        candidates.sort(key=lambda x: x[0][1], reverse=True)\n",
        "        beams = candidates[:beam_width]\n",
        "\n",
        "        # Break if all beams finished\n",
        "        if all(beam[0][0][-1] == end_token for beam in beams):\n",
        "            break\n",
        "\n",
        "    # Combine finished and unfinished beams\n",
        "    all_beams = finished_beams + [beam[0] for beam in beams]\n",
        "    best_seq = max(all_beams, key=lambda x: x[1])[0]\n",
        "\n",
        "    return best_seq  # Return the highest scoring sequence\n",
        "\n",
        "# Training history plotting\n",
        "def plot_training_history(history):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Loss plot\n",
        "    axes[0, 0].plot(history.history['loss'], label='Training Loss')\n",
        "    axes[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    axes[0, 0].set_title('Model Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axes[0, 1].set_title('Model Accuracy')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "\n",
        "    # Learning rate plot\n",
        "    axes[1, 0].plot(history.history['learning_rate'], label='Learning Rate')\n",
        "    axes[1, 0].set_title('Learning Rate')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Learning Rate')\n",
        "    axes[1, 0].set_yscale('log')\n",
        "\n",
        "    # Clean up and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf8d4d6-f5dd-4118-a53a-7c3cd3b53514",
      "metadata": {
        "id": "1cf8d4d6-f5dd-4118-a53a-7c3cd3b53514"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_advanced(encoder_model, decoder_model, q_test, a_test, q_tokenizer, a_tokenizer,\n",
        "                          beam_width=3, temperature=1.0):\n",
        "    smooth = SmoothingFunction().method1\n",
        "    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])\n",
        "\n",
        "    # Initialize metrics\n",
        "    bleu_scores = {f'bleu_{i}': 0.0 for i in range(1, 5)}\n",
        "    rouge_scores = {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "    # Convert test data to tensors once\n",
        "    q_test = tf.convert_to_tensor(q_test, dtype=tf.float32)\n",
        "\n",
        "    # Process in batches for efficiency\n",
        "    batch_size = 32\n",
        "    for i in range(0, len(q_test), batch_size):\n",
        "        batch_end = min(i + batch_size, len(q_test))\n",
        "        batch_q = q_test[i:batch_end]\n",
        "\n",
        "        references = []\n",
        "        hypotheses = []\n",
        "\n",
        "        for j in range(batch_end - i):\n",
        "            # Get reference tokens\n",
        "            reference_tokens = [a_tokenizer.index_word.get(idx, '')\n",
        "                              for idx in a_test[i + j] if idx != 0]\n",
        "            reference_tokens = [token for token in reference_tokens\n",
        "                              if token not in ['<start>', '<end>', '<pad>']]\n",
        "            references.append([reference_tokens])\n",
        "\n",
        "            # Generate response using optimized beam search\n",
        "            decoded_sequence = optimized_beam_search_decode(\n",
        "                encoder_model,\n",
        "                decoder_model,\n",
        "                batch_q[j:j+1],\n",
        "                a_tokenizer,\n",
        "                beam_width=beam_width,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "            decoded_tokens = [a_tokenizer.index_word.get(idx, '')\n",
        "                            for idx in decoded_sequence\n",
        "                            if idx not in [a_tokenizer.word_index.get(t, 0)\n",
        "                                         for t in ['<start>', '<end>', '<pad>']]]\n",
        "            hypotheses.append(decoded_tokens)\n",
        "\n",
        "            # Calculate ROUGE scores\n",
        "            rouge_scores_i = rouge_scorer_instance.score(\n",
        "                ' '.join(reference_tokens),\n",
        "                ' '.join(decoded_tokens)\n",
        "            )\n",
        "            for key in rouge_scores:\n",
        "                rouge_scores[key] += rouge_scores_i[key].fmeasure\n",
        "\n",
        "        # Update BLEU scores for batch\n",
        "        for i in range(1, 5):\n",
        "            bleu_scores[f'bleu_{i}'] += corpus_bleu(\n",
        "                references,\n",
        "                hypotheses,\n",
        "                weights=[1.0/i]*i,\n",
        "                smoothing_function=smooth\n",
        "            ) * len(references)\n",
        "\n",
        "    # Normalize scores\n",
        "    n = len(q_test)\n",
        "    bleu_scores = {k: v/n for k, v in bleu_scores.items()}\n",
        "    rouge_scores = {k: v/n for k, v in rouge_scores.items()}\n",
        "\n",
        "    return bleu_scores, rouge_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd83b1b-ed9b-4ed3-84e3-29340384f015",
      "metadata": {
        "id": "7dd83b1b-ed9b-4ed3-84e3-29340384f015"
      },
      "outputs": [],
      "source": [
        "def ask_question(question, encoder_model, decoder_model, q_tokenizer, a_tokenizer, max_length=150):\n",
        "    question = improved_clean_text(question)\n",
        "\n",
        "    q_seq = q_tokenizer.texts_to_sequences([question])\n",
        "    q_seq = pad_sequences(q_seq, maxlen=MAX_QUESTION_LENGTH, padding='post')\n",
        "\n",
        "    # Get encoder states\n",
        "    encoder_states = encoder_model.predict(q_seq, verbose=0)\n",
        "    if not isinstance(encoder_states, list):\n",
        "        encoder_states = [encoder_states]\n",
        "\n",
        "    # Initialize decoder sequence with start token\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = a_tokenizer.word_index.get('<start>', 0)\n",
        "\n",
        "    decoded_tokens = []\n",
        "    stop_condition = False\n",
        "\n",
        "    while len(decoded_tokens) < max_length and not stop_condition:\n",
        "        # Get decoder outputs\n",
        "        decoder_outputs = decoder_model([target_seq] + encoder_states, verbose=0)\n",
        "\n",
        "        # First output is token probabilities, rest are updated states\n",
        "        output_tokens = decoder_outputs[0]\n",
        "        encoder_states = decoder_outputs[1:]\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = a_tokenizer.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        if sampled_word == '<end>' or sampled_word == '':\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_tokens.append(sampled_word)\n",
        "\n",
        "        # Update target sequence for next iteration\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    return ' '.join(decoded_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a13493-0b9b-46cf-a678-540895785a67",
      "metadata": {
        "id": "a5a13493-0b9b-46cf-a678-540895785a67"
      },
      "outputs": [],
      "source": [
        "class WarmUpLearningRateScheduler(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, warmup_steps, initial_lr):\n",
        "        super().__init__()\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.initial_lr = initial_lr\n",
        "        self.step = 0\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        self.step += 1\n",
        "        if self.step <= self.warmup_steps:\n",
        "            lr = (self.step / self.warmup_steps) * self.initial_lr\n",
        "            self.model.optimizer.learning_rate.assign(lr)\n",
        "\n",
        "callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            min_delta=1e-4\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=10,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model.keras',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        WarmUpLearningRateScheduler(warmup_steps=100, initial_lr=LEARNING_RATE),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ad19a64f-74b9-439f-bc22-5cd2367d479d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ad19a64f-74b9-439f-bc22-5cd2367d479d",
        "outputId": "789bf529-874e-4683-ece1-817849d97ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-046b7564a262>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading and preprocessing data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Dataset:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Loading and preprocessing data...\")\n",
        "# Load data\n",
        "df = load_data(\"dataset\")\n",
        "print(\"Original Dataset:\\n\")\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Preprocess with augmentation\n",
        "augmented_data = []\n",
        "for _, row in df.iterrows():\n",
        "    pairs = advanced_augment_data(row['question'], row['answer'])\n",
        "    augmented_data.extend(pairs)\n",
        "\n",
        "df_augmented = pd.DataFrame(augmented_data, columns=['question', 'answer'])\n",
        "\n",
        "q_data, a_data, q_tokenizer, a_tokenizer = preprocess_data(df_augmented)\n",
        "print(\"Dataset after preprocessing and augmentation:\\n\")\n",
        "print(df_augmented.head())\n",
        "print(df_augmented.info())\n",
        "\n",
        "# Split data\n",
        "indices = np.arange(len(q_data))\n",
        "np.random.shuffle(indices)\n",
        "q_data = q_data[indices]\n",
        "a_data = a_data[indices]\n",
        "\n",
        "num_val = int(len(q_data) * VALIDATION_SPLIT)\n",
        "num_test = int(len(q_data) * TEST_SPLIT)\n",
        "\n",
        "q_train = q_data[:-num_val-num_test]\n",
        "a_train = a_data[:-num_val-num_test]\n",
        "q_val = q_data[-num_val-num_test:-num_test]\n",
        "a_val = a_data[-num_val-num_test:-num_test]\n",
        "q_test = q_data[-num_test:]\n",
        "a_test = a_data[-num_test:]\n",
        "\n",
        "print(\"Building model...\")\n",
        "# Build model\n",
        "model = build_improved_model(len(q_tokenizer.word_index) + 1, len(a_tokenizer.word_index) + 1)\n",
        "\n",
        "print(\"Training model...\")\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    [q_train, a_train[:, :-1]],\n",
        "    a_train[:, 1:],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=([q_val, a_val[:, :-1]], a_val[:, 1:]),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "print(\"Plotting training history...\")\n",
        "plot_training_history(history)\n",
        "\n",
        "# Create inference models\n",
        "print(\"Creating inference models...\")\n",
        "encoder_model, decoder_model = create_inference_models(model, len(a_tokenizer.word_index) + 1)\n",
        "\n",
        "# Save models\n",
        "print(\"Saving models...\")\n",
        "model.save('full_model.keras')\n",
        "encoder_model.save('encoder_model.keras')\n",
        "decoder_model.save('decoder_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fa035e-740e-4d2b-90cb-9328aecabe33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fa035e-740e-4d2b-90cb-9328aecabe33",
        "outputId": "aaf6a7c7-ce76-4c63-cf67-9d5dc5de6d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model...\n",
            "\n",
            "Evaluation Results:\n",
            "BLEU_1: 0.4214\n",
            "BLEU_2: 0.4010\n",
            "BLEU_3: 0.3883\n",
            "BLEU_4: 0.3791\n",
            "ROUGE1: 0.6587\n",
            "ROUGE2: 0.6040\n",
            "ROUGEL: 0.6434\n"
          ]
        }
      ],
      "source": [
        "# Load the encoder and decoder separately\n",
        "encoder_model = load_model('encoder_model.keras')\n",
        "decoder_model = load_model('decoder_model.keras')\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating model...\")\n",
        "bleu_scores, rouge_scores = evaluate_model_advanced(\n",
        "    encoder_model, decoder_model,\n",
        "    q_test, a_test,\n",
        "    q_tokenizer, a_tokenizer,\n",
        "    beam_width=BEAM_WIDTH,\n",
        "    temperature=TEMPERATURE\n",
        ")\n",
        "\n",
        "# Print results\n",
        "print(\"\\nEvaluation Results:\")\n",
        "for metric, score in bleu_scores.items():\n",
        "    print(f\"{metric.upper()}: {score:.4f}\")\n",
        "for metric, score in rouge_scores.items():\n",
        "    print(f\"{metric.upper()}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fafa927-ff7a-40a9-b354-e0be76276aad",
      "metadata": {
        "id": "0fafa927-ff7a-40a9-b354-e0be76276aad",
        "outputId": "7fb33d26-3955-4122-f676-2c81b11cdefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: blockchain is a decentralized digital currency that operates without a central authority or banks. it enables peer-to-peer transactions on a global scale through a network of computers running the bitcoin protocol. transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain. bitcoin\n"
          ]
        }
      ],
      "source": [
        "print(\"Answer:\", ask_question(\"what is blockchain ?\", encoder_model, decoder_model, q_tokenizer, a_tokenizer))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7c791d49-4848-443a-8c9c-60af2c0f5f1e"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (block-query)",
      "language": "python",
      "name": "block-query"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}